{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import ray\n",
    "from ray import tune\n",
    "import ray.tune.progress_reporter as reporter\n",
    "from typing import Optional, Type\n",
    "from ray.rllib.models.torch.torch_modelv2 import TorchModelV2\n",
    "from ray.rllib.models.torch.misc import normc_initializer, SlimFC, SlimConv2d\n",
    "from ray.rllib.utils.annotations import override\n",
    "from ray.rllib.utils.framework import try_import_torch\n",
    "from ray.rllib.utils.typing import ModelConfigDict\n",
    "import ray.rllib.agents.ddpg as ddpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-12 12:57:12,306\tINFO services.py:1245 -- View the Ray dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265\u001b[39m\u001b[22m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'node_ip_address': '10.105.173.195',\n",
       " 'raylet_ip_address': '10.105.173.195',\n",
       " 'redis_address': '10.105.173.195:6379',\n",
       " 'object_store_address': '/tmp/ray/session_2021-08-12_12-57-10_308146_19459/sockets/plasma_store',\n",
       " 'raylet_socket_name': '/tmp/ray/session_2021-08-12_12-57-10_308146_19459/sockets/raylet',\n",
       " 'webui_url': '127.0.0.1:8265',\n",
       " 'session_dir': '/tmp/ray/session_2021-08-12_12-57-10_308146_19459',\n",
       " 'metrics_export_port': 52760,\n",
       " 'node_id': 'd011cf18ec26d65fa574e792aaa9348b5dcb116646829b3a7a9159c5'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch, nn = try_import_torch()\n",
    "ray.init()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################################################\n",
    "###### currently use the default model, which is the fully connected and linear layers\n",
    "#######################################################\n",
    "\n",
    "model = {\"fcnet_hiddens\": [200, 100], \"fcnet_activation\": \"tanh\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################################################\n",
    "##### DDPG config\n",
    "#######################################################\n",
    "\n",
    "config = ddpg.DEFAULT_CONFIG.copy()\n",
    "train_batch_size = 200  ## batch size will be tuned later\n",
    "\n",
    "## customized config\n",
    "\n",
    "config_ddpg = {\n",
    "    \n",
    "    \"num_gpus\": 4,\n",
    "    \"lr\": 1e-5, ## starting low\n",
    "    \"monitor\": True,\n",
    "    \"model\":model,\n",
    "    \"train_batch_size\":train_batch_size,\n",
    "    \"lambda\":0.95,\n",
    "    \"clip_actions\":True,\n",
    "    \"normalize_actions\":True,\n",
    "    \"batch_mode\": \"complete_episodes\", ## or \"truncate_episodes\"\n",
    "    \"no_done_at_end\":True,\n",
    "    \"shuffle_buffer_size\": 200, ## need to be tuned\n",
    "    \"framework\": \"torch\",\n",
    "    \"corrifor_length\": 1,\n",
    "#     \"env\": environment, ## need to be import from custom\n",
    "    \n",
    "    \n",
    "}\n",
    "config.update(config_ddpg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Corridor(gym.Env):\n",
    "    \"\"\"Example of a custom env in which you have to walk down a corridor.\n",
    "    You can configure the length of the corridor via the env config.\"\"\"\n",
    "\n",
    "    def __init__(self, config: EnvContext):\n",
    "        self.end_pos = config[\"corridor_length\"]\n",
    "        self.cur_pos = 0\n",
    "        self.action_space = Discrete(2)\n",
    "        self.observation_space = Box(\n",
    "            0.0, self.end_pos, shape=(1, ), dtype=np.float32)\n",
    "        # Set the seed. This is only used for the final (reach goal) reward.\n",
    "        self.seed(config.worker_index * config.num_workers)\n",
    "\n",
    "    def reset(self):\n",
    "        self.cur_pos = 0\n",
    "        return [self.cur_pos]\n",
    "\n",
    "    def step(self, action):\n",
    "        assert action in [0, 1], action\n",
    "        if action == 0 and self.cur_pos > 0:\n",
    "            self.cur_pos -= 1\n",
    "        elif action == 1:\n",
    "            self.cur_pos += 1\n",
    "        done = self.cur_pos >= self.end_pos\n",
    "        # Produce a random reward when we reach the goal.\n",
    "        return [self.cur_pos], \\\n",
    "            random.random() * 2 if done else -0.1, done, {}\n",
    "\n",
    "    def seed(self, seed=None):\n",
    "        random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() missing 5 required positional arguments: 'obs_space', 'action_space', 'num_outputs', 'model_config', and 'name'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-12ba2a362733>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;31m##nn.Sigmoid()(output)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() missing 5 required positional arguments: 'obs_space', 'action_space', 'num_outputs', 'model_config', and 'name'"
     ]
    }
   ],
   "source": [
    "### define model\n",
    "## only the template\n",
    "class Net(TorchModelV2, nn.Module):\n",
    "    def __init__(self, obs_space: ,\n",
    "                 action_space: ,\n",
    "                 num_outputs: int,\n",
    "                 ModelConfigDict, name:str):\n",
    "        \n",
    "        TorchModelV2.__init__(self, obs_space, action_space, num_outputs,\n",
    "                              model_config, name)\n",
    "        nn.Module.__init__(self)\n",
    "        custom_configs = model_config.get(\"custom_model_config\")\n",
    "        self.flatten = nn.Flatten()\n",
    "        grasp_num = 3  ## need to be specified\n",
    "        self.ls = nn.LSTM(32,64,2, batch_first = True)\n",
    "        self.linear = nn.Linear(64,grasp_num + 7)\n",
    "            \n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size = x.shape[0] \n",
    "        x = self.flatten(x)\n",
    "        x = torch.reshape(x, (batch_size, 100, 32)) \n",
    "        output,(h,c) = self.ls(x)\n",
    "        output = self.linear(h[-1,...]) \n",
    "        return output ##nn.Sigmoid()(output)\n",
    "\n",
    "model = Net()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stopper(trial_num, result):\n",
    "    ### determine when the training will stop\n",
    "    #(when mean reward larger than 50 or episode larger than 1500 will stop train)\n",
    "    return result[\"episode_reward_mean\"] > 50 and result[\"episode_len_mean\"] > 1500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 5.3/15.2 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/8 CPUs, 0/0 GPUs, 0.0/7.01 GiB heap, 0.0/3.51 GiB objects<br>Result logdir: /home/bowen/ray_results/DDPG<br>Number of trials: 1/1 (1 PENDING)<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 5.3/15.2 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/8 CPUs, 0/0 GPUs, 0.0/7.01 GiB heap, 0.0/3.51 GiB objects<br>Result logdir: /home/bowen/ray_results/DDPG<br>Number of trials: 1/1 (1 PENDING)<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 5.3/15.2 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/8 CPUs, 0/0 GPUs, 0.0/7.01 GiB heap, 0.0/3.51 GiB objects<br>Result logdir: /home/bowen/ray_results/DDPG<br>Number of trials: 1/1 (1 PENDING)<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 5.3/15.2 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/8 CPUs, 0/0 GPUs, 0.0/7.01 GiB heap, 0.0/3.51 GiB objects<br>Result logdir: /home/bowen/ray_results/DDPG<br>Number of trials: 1/1 (1 PENDING)<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-12 13:29:09,957\tWARNING tune.py:507 -- SIGINT received (e.g. via Ctrl+C), ending Ray Tune run. This will try to checkpoint the experiment state one last time. Press CTRL+C one more time (or send SIGINT/SIGKILL/SIGTERM) to skip. \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 5.3/15.2 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/8 CPUs, 0/0 GPUs, 0.0/7.01 GiB heap, 0.0/3.51 GiB objects<br>Result logdir: /home/bowen/ray_results/DDPG<br>Number of trials: 1/1 (1 PENDING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name           </th><th>status  </th><th>loc  </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DDPG_None_258bd_00000</td><td>PENDING </td><td>     </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-12 13:29:10,168\tERROR tune.py:546 -- Trials did not complete: [DDPG_None_258bd_00000]\n",
      "2021-08-12 13:29:10,169\tINFO tune.py:550 -- Total run time: 16.84 seconds (16.62 seconds for the tuning loop).\n",
      "2021-08-12 13:29:10,170\tWARNING tune.py:554 -- Experiment has been interrupted, but the most recent state was saved. You can continue running this experiment by passing `resume=True` to `tune.run()`\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<ray.tune.analysis.experiment_analysis.ExperimentAnalysis at 0x7fdc17b32610>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tune.run(\"DDPG\", \n",
    "        config = config,\n",
    "#         local_dir = SAVE_RESULTS_PATH, ## need to be set path when we trained on beast\n",
    "        checkpoint_freq=25,\n",
    "        verbose=2,\n",
    "        checkpoint_at_end=True,\n",
    "        stop=stopper,\n",
    "#         progress_reporter=reporter ## need to be set later\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
