{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import ray\n",
    "from ray import tune\n",
    "import ray.tune.progress_reporter as reporter\n",
    "from typing import Optional, Type\n",
    "from ray.rllib.models.torch.torch_modelv2 import TorchModelV2\n",
    "from ray.rllib.models.torch.misc import normc_initializer, SlimFC, SlimConv2d\n",
    "from ray.rllib.utils.annotations import override\n",
    "from ray.rllib.utils.framework import try_import_torch\n",
    "from ray.rllib.models.catalog import ModelCatalog\n",
    "from ray.rllib.utils.typing import ModelConfigDict\n",
    "import ray.rllib.agents.ddpg as ddpg\n",
    "import numpy as np\n",
    "from ray.rllib.models.torch.misc import SlimFC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-13 00:25:58,611\tINFO services.py:1245 -- View the Ray dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265\u001b[39m\u001b[22m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'node_ip_address': '192.168.1.72',\n",
       " 'raylet_ip_address': '192.168.1.72',\n",
       " 'redis_address': '192.168.1.72:6379',\n",
       " 'object_store_address': '/tmp/ray/session_2021-08-13_00-25-57_145541_38969/sockets/plasma_store',\n",
       " 'raylet_socket_name': '/tmp/ray/session_2021-08-13_00-25-57_145541_38969/sockets/raylet',\n",
       " 'webui_url': '127.0.0.1:8265',\n",
       " 'session_dir': '/tmp/ray/session_2021-08-13_00-25-57_145541_38969',\n",
       " 'metrics_export_port': 57852,\n",
       " 'node_id': 'a2ceb2142f9f6297b9936dc16bf8f19557f999d3cacaf4b64eb4713a'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch, nn = try_import_torch()\n",
    "ray.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################\n",
    "#### Environment\n",
    "############################\n",
    "\n",
    "class Corridor(gym.Env):\n",
    "    \"\"\"Example of a custom env in which you have to walk down a corridor.\n",
    "    You can configure the length of the corridor via the env config.\"\"\"\n",
    "\n",
    "    def __init__(self, config: EnvContext):\n",
    "        self.end_pos = config[\"corridor_length\"]\n",
    "        self.cur_pos = 0\n",
    "        self.n = 100\n",
    "        self.action_space = np.linspace(-1, 1, self.n)\n",
    "        self.observation_space = np.linspace(-1, 1, self.n)\n",
    "        # Set the seed. This is only used for the final (reach goal) reward.\n",
    "#         self.seed(config.worker_index * config.num_workers)\n",
    "\n",
    "    def reset(self):\n",
    "        self.cur_pos = 0\n",
    "        return [self.cur_pos]\n",
    "\n",
    "    def step(self, action):\n",
    "        assert action in [0, 1], action\n",
    "        if action == 0 and self.cur_pos > 0:\n",
    "            self.cur_pos -= 1\n",
    "        elif action == 1:\n",
    "            self.cur_pos += 1\n",
    "        done = self.cur_pos >= self.end_pos\n",
    "        # Produce a random reward when we reach the goal.\n",
    "        return [self.cur_pos], \\\n",
    "            random.random() * 2 if done else -0.1, done, {}\n",
    "\n",
    "    def seed(self, seed=None):\n",
    "        random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################################################\n",
    "###### MODEL: LSTM + linear\n",
    "#######################################################\n",
    "\n",
    "class Net(TorchModelV2, nn.Module):\n",
    "    def __init__(self, obs_space, action_space, num_outputs, model_config,\n",
    "                 name):\n",
    "        \n",
    "        TorchModelV2.__init__(self, obs_space, action_space, num_outputs, model_config, name)\n",
    "        nn.Module.__init__(self)\n",
    "        \n",
    "        custom_configs = model_config.get(\"custom_model_config\")\n",
    "\n",
    "        self.size_in = 32; ## 16+16\n",
    "        self.lstm_state_size = 64\n",
    "        self.grab_location = 1\n",
    "        self.lstm = nn.LSTM(self.size_in, self.lstm_state_size, batch_first=True)\n",
    "        self.num_outputs = self.grab_location + 7 ## one grab location + seven (position + translation)\n",
    "\n",
    "        # Postprocess LSTM output with another hidden layer and compute values.\n",
    "        self.linear = SlimFC(self.lstm_state_size, self.num_outputs)\n",
    "        \n",
    "            \n",
    "\n",
    "    def forward(self, inputs, state, seq_lens):\n",
    "        ## input will be (size 32, 16 for desired trajectory + another 16 for final trajectory config)\n",
    "        ## state will be (grasp locations + position + orientation) current\n",
    "        \n",
    "        batch_size = x.shape[0] \n",
    "        x = self.flatten(x)\n",
    "        x = torch.reshape(x, (batch_size, 100, 16+16)) \n",
    "        \n",
    "        # Forward through LSTM.\n",
    "        output, [h, c] = self.lstm(x, state)\n",
    "        \n",
    "        # Forward LSTM output\n",
    "        output = self.linear(h[-1,...])\n",
    "        return nn.Tanh()(output)  ## squeeze the output from -1 to 1\n",
    "        \n",
    "        \n",
    "\n",
    "ModelCatalog.register_custom_model(\"my_model\", Net)\n",
    "model = {\"custom_model\":\"my_model\"}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################################################\n",
    "##### DDPG config\n",
    "#######################################################\n",
    "\n",
    "config = ddpg.DEFAULT_CONFIG.copy()\n",
    "train_batch_size = 200  ## batch size will be tuned later\n",
    "\n",
    "config_ddpg = {\n",
    "    \n",
    "    \"num_gpus\": 4,\n",
    "    \"lr\": 1e-5, ## starting low\n",
    "    \"monitor\": True,\n",
    "    \"model\":model,\n",
    "    \"train_batch_size\":train_batch_size,\n",
    "    \"lambda\":0.95,\n",
    "    \"clip_actions\":True,\n",
    "    \"normalize_actions\":True,\n",
    "    \"batch_mode\": \"complete_episodes\", ## or \"truncate_episodes\"\n",
    "    \"no_done_at_end\":True,\n",
    "    \"shuffle_buffer_size\": 200, ## need to be tuned\n",
    "    \"framework\": \"torch\",\n",
    "    \"corridor_length\": 1,\n",
    "#     \"env\": environment, ## need to be import from custom\n",
    "    \n",
    "    \n",
    "}\n",
    "config.update(config_ddpg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stopper(trial_num, result):\n",
    "    ### determine when the training will stop\n",
    "    #(when mean reward larger than 50 or episode larger than 1500 will stop train)\n",
    "    return result[\"episode_reward_mean\"] > 50 and result[\"episode_len_mean\"] > 1500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 5.9/15.2 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/8 CPUs, 0/0 GPUs, 0.0/6.74 GiB heap, 0.0/3.37 GiB objects<br>Result logdir: /home/bowen/ray_results/DDPG<br>Number of trials: 1/1 (1 PENDING)<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 5.9/15.2 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/8 CPUs, 0/0 GPUs, 0.0/6.74 GiB heap, 0.0/3.37 GiB objects<br>Result logdir: /home/bowen/ray_results/DDPG<br>Number of trials: 1/1 (1 PENDING)<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-13 00:51:05,334\tWARNING tune.py:507 -- SIGINT received (e.g. via Ctrl+C), ending Ray Tune run. This will try to checkpoint the experiment state one last time. Press CTRL+C one more time (or send SIGINT/SIGKILL/SIGTERM) to skip. \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 5.9/15.2 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/8 CPUs, 0/0 GPUs, 0.0/6.74 GiB heap, 0.0/3.37 GiB objects<br>Result logdir: /home/bowen/ray_results/DDPG<br>Number of trials: 1/1 (1 PENDING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name           </th><th>status  </th><th>loc  </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DDPG_None_6fc1e_00000</td><td>PENDING </td><td>     </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-13 00:51:05,545\tERROR tune.py:546 -- Trials did not complete: [DDPG_None_6fc1e_00000]\n",
      "2021-08-13 00:51:05,547\tINFO tune.py:550 -- Total run time: 5.52 seconds (5.25 seconds for the tuning loop).\n",
      "2021-08-13 00:51:05,548\tWARNING tune.py:554 -- Experiment has been interrupted, but the most recent state was saved. You can continue running this experiment by passing `resume=True` to `tune.run()`\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<ray.tune.analysis.experiment_analysis.ExperimentAnalysis at 0x7fb1941bc220>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### training\n",
    "\n",
    "tune.run(\"DDPG\", \n",
    "        config = config,\n",
    "#         local_dir = SAVE_RESULTS_PATH, ## need to be set path when we trained on beast\n",
    "        checkpoint_freq=25,\n",
    "        verbose=2,\n",
    "        checkpoint_at_end=True,\n",
    "        stop=stopper,\n",
    "#         progress_reporter=reporter ## need to be set later\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
