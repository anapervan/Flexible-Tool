{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import load\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.linalg import norm\n",
    "from PIL import Image\n",
    "from numpy import asarray\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### import data from csv (written in data_processing)\n",
    "q_array = load('q_array0.npy')\n",
    "a_array = load('a_array0.npy')\n",
    "N = 100\n",
    "\n",
    "### find number of trials\n",
    "data_trials = int(a_array.shape[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 16)\n",
      "(100, 6)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "q_array = np.resize(q_array,((N,16,100)))\n",
    "a_array = np.resize(a_array,((N,6)))\n",
    "q_array_end = np.zeros((N,16))\n",
    "for i in range(N):\n",
    "    q_array_end[i,:] = q_array[i,:,-1]\n",
    "print(q_array_end.shape)\n",
    "print(a_array.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## Open the image form working directory\n",
    "\n",
    "xy_array = np.zeros((N,288,432,4))\n",
    "xz_array = np.zeros((N,288,432,4))\n",
    "\n",
    "for i in range(N):\n",
    "    \n",
    "    img1 = Image.open('/home/bowen/Documents/Rod_manipulation/Flexible-Tool/png_data/'+str(i)+'_xy.png')\n",
    "    img2 = Image.open('/home/bowen/Documents/Rod_manipulation/Flexible-Tool/png_data/'+str(i)+'_xz.png')\n",
    "\n",
    "    xy_array[i,:,:,:] = asarray(img1)\n",
    "    xz_array[i,:,:,:] = asarray(img2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 288, 432, 1)\n",
      "(100, 288, 432, 1)\n",
      "(100, 2, 288, 432)\n"
     ]
    }
   ],
   "source": [
    "## load the image data into numpy arries and transfer RGBA channels into one channel by taking mean of RGB data.\n",
    "## May have function directly address this channel transfer (check later)\n",
    "for k in range(N):\n",
    "    xy_array[k,:,:,0] = np.mean(xy_array[k,:,:,0] + xy_array[k,:,:,1] + xy_array[k,:,:,2])\n",
    "    xz_array[k,:,:,0] = np.mean(xz_array[k,:,:,0] + xz_array[k,:,:,1] + xz_array[k,:,:,2])\n",
    "\n",
    "xy_array = np.resize(xy_array,(N,288,432,1))\n",
    "xz_array = np.resize(xz_array,(N,288,432,1))\n",
    "print(xy_array.shape)\n",
    "print(xz_array.shape)\n",
    "\n",
    "## put two image arraies into one single array with two channels and then reshape it because of the format of pytorch\n",
    "image_array = np.stack([xy_array,xz_array], axis = -1).squeeze()\n",
    "image_array = np.transpose(image_array,[0,3,1,2]) ## change the axis\n",
    "print(image_array.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with np.printoptions(threshold=np.inf):\n",
    "    \n",
    "#     print(xy_array(0,288,432,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 1, 16)\n",
      "80\n",
      "80\n",
      "batch 0\n",
      "Shape of x:  torch.Size([5, 16]) torch.float32\n",
      "Shape of y:  torch.Size([5, 6]) torch.float32\n"
     ]
    }
   ],
   "source": [
    "## split q_end(end configurations) and a_array into test and train set and put them into tensor and dataloader\n",
    "\n",
    "\n",
    "qend_train_x = (q_array_end[0:int(0.8*N),:]).astype(np.float32)\n",
    "\n",
    "qend_test_x = (q_array_end[int(0.8*N):N,:]).astype(np.float32) \n",
    "qend_test_x = np.expand_dims(qend_test_x, 1) # add dimension for neural net\n",
    "print(qend_test_x.shape)\n",
    "\n",
    "train_y = (a_array[0:int(0.8*N),:]).astype(np.float32)\n",
    "test_y = (a_array[int(0.8*N):N,:]).astype(np.float32)\n",
    "\n",
    "qx_test_tensor = torch.from_numpy(qend_test_x)\n",
    "y_test_tensor = torch.from_numpy(test_y)\n",
    "test_data_qtoa = [(qx_test_tensor[i],y_test_tensor[i]) for i in range(qx_test_tensor.shape[0])]\n",
    "\n",
    "qx_train_tensor = torch.from_numpy(qend_train_x)\n",
    "y_train_tensor = torch.from_numpy(train_y)\n",
    "\n",
    "print(qx_train_tensor.size(0))\n",
    "print(y_train_tensor.size(0))\n",
    "\n",
    "\n",
    "q_train_dataset = torch.utils.data.TensorDataset(qx_train_tensor, y_train_tensor)\n",
    "q_test_dataset = torch.utils.data.TensorDataset(qx_test_tensor, y_test_tensor)\n",
    "\n",
    "q_train_loader = torch.utils.data.DataLoader(q_train_dataset, batch_size = 5, shuffle=True)\n",
    "q_test_loader = torch.utils.data.DataLoader(q_test_dataset, batch_size = 5, shuffle=True)\n",
    "\n",
    "for batch, (x, y) in enumerate(q_train_loader):\n",
    "    print(\"batch\", batch)\n",
    "    print(\"Shape of x: \", x.shape, x.dtype)\n",
    "    print(\"Shape of y: \", y.shape, y.dtype)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 0\n",
      "Shape of x:  torch.Size([5, 2, 288, 432]) torch.float32\n",
      "Shape of y:  torch.Size([5, 6]) torch.float32\n"
     ]
    }
   ],
   "source": [
    "## split q_end(end configurations) and a_array into test and train set and put them into tensor and dataloader\n",
    "image_train_x = (image_array[0:int(0.8*N),:,:,:]).astype(np.float32) \n",
    "image_test_x = (image_array[int(0.8*N):N,:,:,:]).astype(np.float32) \n",
    "image_test_x = np.expand_dims(image_test_x, 1) # add dimension for neural net\n",
    "\n",
    "\n",
    "imagex_test_tensor = torch.from_numpy(image_test_x)\n",
    "\n",
    "test_data = [(imagex_test_tensor[i],y_test_tensor[i]) for i in range(imagex_test_tensor.shape[0])]\n",
    "\n",
    "imagex_train_tensor = torch.from_numpy(image_train_x)\n",
    "\n",
    "\n",
    "\n",
    "image_train_dataset = torch.utils.data.TensorDataset(imagex_train_tensor, y_train_tensor)\n",
    "image_test_dataset = torch.utils.data.TensorDataset(imagex_test_tensor, y_test_tensor)\n",
    "\n",
    "image_train_loader = torch.utils.data.DataLoader(image_train_dataset, batch_size = 5, shuffle=True)\n",
    "image_test_loader = torch.utils.data.DataLoader(image_test_dataset, batch_size = 5, shuffle=True)\n",
    "\n",
    "for batch, (x, y) in enumerate(image_train_loader):\n",
    "    print(\"batch\", batch)\n",
    "    print(\"Shape of x: \", x.shape, x.dtype)\n",
    "    print(\"Shape of y: \", y.shape, y.dtype)\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "\n",
    "        self.pool = nn.MaxPool3d(2)\n",
    "        self.relu = nn.ReLU\n",
    "\n",
    "        self.conv1 = nn.Conv3d(in_channels=2, out_channels=16, kernel_size=3)\n",
    "        self.conv2 = nn.Conv3d(in_channels=16, out_channels=32, kernel_size=3)\n",
    "        self.conv3 = nn.Conv3d(in_channels=32, out_channels=32, kernel_size=3)\n",
    "        self.conv4 = nn.Conv3d(in_channels=32, out_channels=64, kernel_size=3)\n",
    "        self.conv5 = nn.Conv3d(in_channels=64, out_channels=128, kernel_size=3)\n",
    "\n",
    "        ## the input features should be the flatten version of the outchannel from the last conv3d layer\n",
    "        self.linear1 = nn.Linear(12*4*4, 128)\n",
    "        self.linear2 = nn.Linear(128, 32)\n",
    "        self.linear3 = nn.Linear(32, 6)\n",
    "\n",
    "    def forward(self, img, q):\n",
    "\n",
    "        img_out = self.pool(self.relu(self.conv1(img)))\n",
    "        img_out = self.pool(self.relu(self.conv2(img_out)))\n",
    "        img_out = self.pool(self.relu(self.conv3(img_out)))\n",
    "        img_out = self.pool(self.relu(self.conv4(img_out)))\n",
    "        img_out = self.pool(self.relu(self.conv5(img_out)))\n",
    "\n",
    "        img_out = nn.Flatten()(img_out)\n",
    "\n",
    "        concat = torch.cat([img_out, q], 1)\n",
    "\n",
    "        output = self.relu(self.linear1(concat))\n",
    "        output = self.relu(self.linear2(concat))\n",
    "        output = nn.Sigmoid()(self.linear3(concat))\n",
    "\n",
    "        return output\n",
    "model = Net()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
