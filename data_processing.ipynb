{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# df = pd.read_csv('/home/bowen/Documents/Rod_manipulation/Flexible-Tool/data_2.csv', sep = \" \", names = ['name', 'value'])\n",
    "\n",
    "df = pd.read_csv('/home/bowen/Documents/Rod_manipulation/Flexible-Tool/data_2.csv', sep = \" \", names = ['name', 'value'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a</td>\n",
       "      <td>[0.6152792  0.57624728 0.97183159 0.30227324 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>q</td>\n",
       "      <td>[[1.0, 0.99996588008, 0.99989695401, 0.9997925...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>det_J</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, -2.53263925567196e-87, 2....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a</td>\n",
       "      <td>[0.42157321 0.04321076 0.28883865 0.53631535 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>q</td>\n",
       "      <td>[[1.0, 0.99999984126, 0.99999948152, 0.9999988...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2995</th>\n",
       "      <td>q</td>\n",
       "      <td>[[1.0, 0.99991970255, 0.99975684995, 0.9995091...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2996</th>\n",
       "      <td>det_J</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 1.4138451607417442e-86, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2997</th>\n",
       "      <td>a</td>\n",
       "      <td>[0.18525751 0.06743073 0.86360801 0.0865571  0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2998</th>\n",
       "      <td>q</td>\n",
       "      <td>[[1.0, 0.99999969828, 0.9999992522, 0.99999881...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2999</th>\n",
       "      <td>det_J</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 5.221002520645936e-85, 1....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       name                                              value\n",
       "0         a  [0.6152792  0.57624728 0.97183159 0.30227324 0...\n",
       "1         q  [[1.0, 0.99996588008, 0.99989695401, 0.9997925...\n",
       "2     det_J  [0.0, 0.0, 0.0, 0.0, -2.53263925567196e-87, 2....\n",
       "3         a  [0.42157321 0.04321076 0.28883865 0.53631535 0...\n",
       "4         q  [[1.0, 0.99999984126, 0.99999948152, 0.9999988...\n",
       "...     ...                                                ...\n",
       "2995      q  [[1.0, 0.99991970255, 0.99975684995, 0.9995091...\n",
       "2996  det_J  [0.0, 0.0, 0.0, 0.0, 1.4138451607417442e-86, -...\n",
       "2997      a  [0.18525751 0.06743073 0.86360801 0.0865571  0...\n",
       "2998      q  [[1.0, 0.99999969828, 0.9999992522, 0.99999881...\n",
       "2999  det_J  [0.0, 0.0, 0.0, 0.0, 5.221002520645936e-85, 1....\n",
       "\n",
       "[3000 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df.dropna(inplace = True)\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.DataFrame()\n",
    "for r in range(len(df)):\n",
    "    if r % 3 == 0:\n",
    "        df0 = df.iloc[r,1:]\n",
    "        df0.value\n",
    "        df0 = df0.str.strip('[[[ ')\n",
    "        df0 = df0.str.strip('[]')\n",
    "        df0 = df0.value.split()\n",
    "        df0 = np.array(df0,dtype=float)\n",
    "        df2 = df2.append(pd.DataFrame(df0))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6000, 1)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.head(12)\n",
    "df2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6000, 1)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = pd.DataFrame()\n",
    "for i in range(len(df)):\n",
    "    if i % 3 == 1:\n",
    "        df1 = df.iloc[i,1:]\n",
    "        df1 = df1.value\n",
    "        df1 = df1.replace('[','')\n",
    "        df1 = df1.replace(']','')\n",
    "        df1 = df1.split(',')\n",
    "        df1 = np.array(df1,dtype=float)\n",
    "        df3 = df3.append(pd.DataFrame(df1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1600000, 1)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_array = df3.to_numpy()\n",
    "tmp = []\n",
    "for r in q_array:\n",
    "    tmp.append(np.transpose(np.asarray([r])).astype(np.float32))\n",
    "q_array = np.asarray(tmp.copy())\n",
    "type(q_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 16, 100)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_array = q_array.reshape(1000,16,100)\n",
    "q_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_array = df2.to_numpy()\n",
    "tmp2 = []\n",
    "for i in a_array:\n",
    "    tmp2.append(np.transpose(np.asarray([i])).astype(np.float32))\n",
    "a_array = np.asarray(tmp2.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 6)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_array = a_array.reshape(1000,6)\n",
    "a_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = (q_array[0:800,:,:]).astype(np.float32) # training data from csv/pandas (80% of existing data?)\n",
    "test_x = (q_array[800:1000,:,:]).astype(np.float32) # test data from csv/pandas (remaining ~20% of data)\n",
    "test_x = np.expand_dims(test_x, 1) # add dimension for neural net\n",
    "\n",
    "train_y = (a_array[0:800,:]).astype(np.float32)\n",
    "test_y = (a_array[800:1000,:]).astype(np.float32)\n",
    "\n",
    "x_test_tensor = torch.from_numpy(test_x)\n",
    "y_test_tensor = torch.from_numpy(test_y)\n",
    "test_data = [(x_test_tensor[i],y_test_tensor[i]) for i in range(x_test_tensor.shape[0])]\n",
    "\n",
    "# print(train_x.shape)\n",
    "# print(x_test_tensor.shape)\n",
    "# print(y_test_tensor.shape)\n",
    "# print(len(test_data))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 0\n",
      "Shape of x:  torch.Size([100, 16, 100]) torch.float32\n",
      "Shape of y:  torch.Size([100, 6]) torch.float32\n"
     ]
    }
   ],
   "source": [
    "x_train_tensor = torch.from_numpy(train_x)\n",
    "y_train_tensor = torch.from_numpy(train_y)\n",
    "\n",
    "# xtrain_tensor = torch.utils.data.TensorDataset(train_x)\n",
    "# ytrain_tensor = torch.utils.data.TensorDataset(train_y)\n",
    "\n",
    "train_dataset = torch.utils.data.TensorDataset(x_train_tensor, y_train_tensor)\n",
    "test_dataset = torch.utils.data.TensorDataset(x_test_tensor, y_test_tensor)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size = 100,shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size = 100, \n",
    "                                             shuffle=True)\n",
    "\n",
    "\n",
    "for batch, (x, y) in enumerate(train_loader):\n",
    "    print(\"batch\", batch)\n",
    "    print(\"Shape of x: \", x.shape, x.dtype)\n",
    "    print(\"Shape of y: \", y.shape, y.dtype)\n",
    "    break\n",
    "\n",
    "\n",
    "# trainset_x = torch.utils.data.DataLoader(train_x, batch_size=10, shuffle=True)\n",
    "# testset_x = torch.utils.data.DataLoader(test_x, batch_size=10, shuffle=True)\n",
    "# trainset_y = torch.utils.data.DataLoader(train_y, batch_size=10, shuffle=True)\n",
    "# testset_y = torch.utils.data.DataLoader(test_y, batch_size=10, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (ls): LSTM(16, 32, num_layers=2, batch_first=True)\n",
      "  (linear): Linear(in_features=32, out_features=6, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "            \n",
    "        self.ls = nn.LSTM(16,32,2, batch_first = True)\n",
    "        self.linear = nn.Linear(32,6)\n",
    "            \n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size = x.shape[0] \n",
    "        x = self.flatten(x)\n",
    "        x = torch.reshape(x, (batch_size, 100, 16)) \n",
    "        output,(h,c) = self.ls(x)\n",
    "        output = self.linear(h[-1,...]) \n",
    "        return nn.Sigmoid()(output)\n",
    "\n",
    "model = Net()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "### loss function and optimizer for training \n",
    "loss_fn = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-2)\n",
    "\n",
    "### Functions for training and testing the model\n",
    "def train(dataloader, model, loss_fn, optimizer,loss_list):\n",
    "    size = len(dataloader.dataset)\n",
    "    for batch, (x,y) in enumerate(dataloader):\n",
    "\n",
    "#         print(\"batch \", batch)\n",
    "#         print(\"Shape of x: \", x.shape)\n",
    "#         print(\"Shape of y: \", y.shape)\n",
    "    \n",
    "        # Compute prediction error\n",
    "        pred = model(x)\n",
    "#         print(\"pred\", pred)\n",
    "#         print(\"y\", y)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch % 2 == 0:\n",
    "            loss, current = loss.item(), batch * len(x)\n",
    "            loss_list.append(loss)\n",
    "        if batch % 2 == 0:\n",
    "#             loss, current = loss.item(), batch * len(x)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "    return loss_list\n",
    "\n",
    "def test(dataloader, model,test_loss_list):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            pred = model(X)\n",
    "#             print(\"pred\",pred.shape)\n",
    "#             print(\"y\",y.shape)\n",
    "            test_loss += loss_fn(pred, y)\n",
    "    print(f\"Test Error: Loss = {test_loss:>8f} \\n\")\n",
    "    test_loss_list.append(test_loss)\n",
    "    return test_loss_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 0.085192  [    0/  800]\n",
      "loss: 0.082811  [  200/  800]\n",
      "loss: 0.077863  [  400/  800]\n",
      "loss: 0.088803  [  600/  800]\n",
      "Test Error: Loss = 0.171954 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.082359  [    0/  800]\n",
      "loss: 0.085543  [  200/  800]\n",
      "loss: 0.082167  [  400/  800]\n",
      "loss: 0.085189  [  600/  800]\n",
      "Test Error: Loss = 0.172849 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.088290  [    0/  800]\n",
      "loss: 0.083696  [  200/  800]\n",
      "loss: 0.079401  [  400/  800]\n",
      "loss: 0.081130  [  600/  800]\n",
      "Test Error: Loss = 0.172458 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.087447  [    0/  800]\n",
      "loss: 0.087434  [  200/  800]\n",
      "loss: 0.083302  [  400/  800]\n",
      "loss: 0.084401  [  600/  800]\n",
      "Test Error: Loss = 0.172194 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.084649  [    0/  800]\n",
      "loss: 0.087554  [  200/  800]\n",
      "loss: 0.080498  [  400/  800]\n",
      "loss: 0.086329  [  600/  800]\n",
      "Test Error: Loss = 0.173345 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.086847  [    0/  800]\n",
      "loss: 0.086506  [  200/  800]\n",
      "loss: 0.084553  [  400/  800]\n",
      "loss: 0.079540  [  600/  800]\n",
      "Test Error: Loss = 0.172422 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.084445  [    0/  800]\n",
      "loss: 0.088508  [  200/  800]\n",
      "loss: 0.084393  [  400/  800]\n",
      "loss: 0.081269  [  600/  800]\n",
      "Test Error: Loss = 0.171935 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.086845  [    0/  800]\n",
      "loss: 0.078416  [  200/  800]\n",
      "loss: 0.091342  [  400/  800]\n",
      "loss: 0.088875  [  600/  800]\n",
      "Test Error: Loss = 0.171034 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.081944  [    0/  800]\n",
      "loss: 0.083985  [  200/  800]\n",
      "loss: 0.080976  [  400/  800]\n",
      "loss: 0.072341  [  600/  800]\n",
      "Test Error: Loss = 0.151994 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.075423  [    0/  800]\n",
      "loss: 0.072022  [  200/  800]\n",
      "loss: 0.075052  [  400/  800]\n",
      "loss: 0.071339  [  600/  800]\n",
      "Test Error: Loss = 0.145881 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 0.071800  [    0/  800]\n",
      "loss: 0.073573  [  200/  800]\n",
      "loss: 0.069822  [  400/  800]\n",
      "loss: 0.071941  [  600/  800]\n",
      "Test Error: Loss = 0.143258 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 0.069343  [    0/  800]\n",
      "loss: 0.071966  [  200/  800]\n",
      "loss: 0.069636  [  400/  800]\n",
      "loss: 0.070933  [  600/  800]\n",
      "Test Error: Loss = 0.142067 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 0.066462  [    0/  800]\n",
      "loss: 0.073480  [  200/  800]\n",
      "loss: 0.070576  [  400/  800]\n",
      "loss: 0.070757  [  600/  800]\n",
      "Test Error: Loss = 0.142397 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 0.068908  [    0/  800]\n",
      "loss: 0.069626  [  200/  800]\n",
      "loss: 0.069329  [  400/  800]\n",
      "loss: 0.069189  [  600/  800]\n",
      "Test Error: Loss = 0.139925 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 0.067022  [    0/  800]\n",
      "loss: 0.064528  [  200/  800]\n",
      "loss: 0.065680  [  400/  800]\n",
      "loss: 0.073632  [  600/  800]\n",
      "Test Error: Loss = 0.138915 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 0.070533  [    0/  800]\n",
      "loss: 0.069580  [  200/  800]\n",
      "loss: 0.064412  [  400/  800]\n",
      "loss: 0.065836  [  600/  800]\n",
      "Test Error: Loss = 0.139481 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 0.066995  [    0/  800]\n",
      "loss: 0.070694  [  200/  800]\n",
      "loss: 0.069636  [  400/  800]\n",
      "loss: 0.068678  [  600/  800]\n",
      "Test Error: Loss = 0.137591 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 0.067243  [    0/  800]\n",
      "loss: 0.071056  [  200/  800]\n",
      "loss: 0.068089  [  400/  800]\n",
      "loss: 0.069327  [  600/  800]\n",
      "Test Error: Loss = 0.147370 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 0.070652  [    0/  800]\n",
      "loss: 0.073376  [  200/  800]\n",
      "loss: 0.066101  [  400/  800]\n",
      "loss: 0.071362  [  600/  800]\n",
      "Test Error: Loss = 0.132790 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 0.066116  [    0/  800]\n",
      "loss: 0.070874  [  200/  800]\n",
      "loss: 0.065617  [  400/  800]\n",
      "loss: 0.063591  [  600/  800]\n",
      "Test Error: Loss = 0.131661 \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "loss: 0.063951  [    0/  800]\n",
      "loss: 0.063557  [  200/  800]\n",
      "loss: 0.060190  [  400/  800]\n",
      "loss: 0.063181  [  600/  800]\n",
      "Test Error: Loss = 0.126636 \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "loss: 0.063462  [    0/  800]\n",
      "loss: 0.060171  [  200/  800]\n",
      "loss: 0.056806  [  400/  800]\n",
      "loss: 0.061546  [  600/  800]\n",
      "Test Error: Loss = 0.144918 \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "loss: 0.069781  [    0/  800]\n",
      "loss: 0.056831  [  200/  800]\n",
      "loss: 0.059729  [  400/  800]\n",
      "loss: 0.060286  [  600/  800]\n",
      "Test Error: Loss = 0.121157 \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "loss: 0.061489  [    0/  800]\n",
      "loss: 0.065543  [  200/  800]\n",
      "loss: 0.057092  [  400/  800]\n",
      "loss: 0.059566  [  600/  800]\n",
      "Test Error: Loss = 0.120234 \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "loss: 0.059859  [    0/  800]\n",
      "loss: 0.058675  [  200/  800]\n",
      "loss: 0.055767  [  400/  800]\n",
      "loss: 0.060633  [  600/  800]\n",
      "Test Error: Loss = 0.119075 \n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "loss: 0.056764  [    0/  800]\n",
      "loss: 0.062424  [  200/  800]\n",
      "loss: 0.060184  [  400/  800]\n",
      "loss: 0.055177  [  600/  800]\n",
      "Test Error: Loss = 0.118408 \n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "loss: 0.056158  [    0/  800]\n",
      "loss: 0.057156  [  200/  800]\n",
      "loss: 0.060078  [  400/  800]\n",
      "loss: 0.056933  [  600/  800]\n",
      "Test Error: Loss = 0.118463 \n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "loss: 0.057000  [    0/  800]\n",
      "loss: 0.058171  [  200/  800]\n",
      "loss: 0.056078  [  400/  800]\n",
      "loss: 0.061597  [  600/  800]\n",
      "Test Error: Loss = 0.117123 \n",
      "\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "loss: 0.053738  [    0/  800]\n",
      "loss: 0.057157  [  200/  800]\n",
      "loss: 0.057405  [  400/  800]\n",
      "loss: 0.056132  [  600/  800]\n",
      "Test Error: Loss = 0.116854 \n",
      "\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "loss: 0.059878  [    0/  800]\n",
      "loss: 0.057590  [  200/  800]\n",
      "loss: 0.053204  [  400/  800]\n",
      "loss: 0.053238  [  600/  800]\n",
      "Test Error: Loss = 0.116102 \n",
      "\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "loss: 0.056231  [    0/  800]\n",
      "loss: 0.057164  [  200/  800]\n",
      "loss: 0.052171  [  400/  800]\n",
      "loss: 0.055337  [  600/  800]\n",
      "Test Error: Loss = 0.115060 \n",
      "\n",
      "Epoch 32\n",
      "-------------------------------\n",
      "loss: 0.054007  [    0/  800]\n",
      "loss: 0.057934  [  200/  800]\n",
      "loss: 0.055096  [  400/  800]\n",
      "loss: 0.057160  [  600/  800]\n",
      "Test Error: Loss = 0.113670 \n",
      "\n",
      "Epoch 33\n",
      "-------------------------------\n",
      "loss: 0.051296  [    0/  800]\n",
      "loss: 0.053868  [  200/  800]\n",
      "loss: 0.056017  [  400/  800]\n",
      "loss: 0.058857  [  600/  800]\n",
      "Test Error: Loss = 0.114663 \n",
      "\n",
      "Epoch 34\n",
      "-------------------------------\n",
      "loss: 0.053592  [    0/  800]\n",
      "loss: 0.053629  [  200/  800]\n",
      "loss: 0.054722  [  400/  800]\n",
      "loss: 0.051693  [  600/  800]\n",
      "Test Error: Loss = 0.114990 \n",
      "\n",
      "Epoch 35\n",
      "-------------------------------\n",
      "loss: 0.053868  [    0/  800]\n",
      "loss: 0.059956  [  200/  800]\n",
      "loss: 0.052440  [  400/  800]\n",
      "loss: 0.054336  [  600/  800]\n",
      "Test Error: Loss = 0.113595 \n",
      "\n",
      "Epoch 36\n",
      "-------------------------------\n",
      "loss: 0.058630  [    0/  800]\n",
      "loss: 0.051023  [  200/  800]\n",
      "loss: 0.054120  [  400/  800]\n",
      "loss: 0.051410  [  600/  800]\n",
      "Test Error: Loss = 0.110315 \n",
      "\n",
      "Epoch 37\n",
      "-------------------------------\n",
      "loss: 0.053457  [    0/  800]\n",
      "loss: 0.052212  [  200/  800]\n",
      "loss: 0.054454  [  400/  800]\n",
      "loss: 0.053470  [  600/  800]\n",
      "Test Error: Loss = 0.112279 \n",
      "\n",
      "Epoch 38\n",
      "-------------------------------\n",
      "loss: 0.056263  [    0/  800]\n",
      "loss: 0.050743  [  200/  800]\n",
      "loss: 0.057078  [  400/  800]\n",
      "loss: 0.055667  [  600/  800]\n",
      "Test Error: Loss = 0.114268 \n",
      "\n",
      "Epoch 39\n",
      "-------------------------------\n",
      "loss: 0.051699  [    0/  800]\n",
      "loss: 0.050162  [  200/  800]\n",
      "loss: 0.051655  [  400/  800]\n",
      "loss: 0.053145  [  600/  800]\n",
      "Test Error: Loss = 0.114023 \n",
      "\n",
      "Epoch 40\n",
      "-------------------------------\n",
      "loss: 0.052644  [    0/  800]\n",
      "loss: 0.054311  [  200/  800]\n",
      "loss: 0.053337  [  400/  800]\n",
      "loss: 0.048426  [  600/  800]\n",
      "Test Error: Loss = 0.115265 \n",
      "\n",
      "Epoch 41\n",
      "-------------------------------\n",
      "loss: 0.051810  [    0/  800]\n",
      "loss: 0.055030  [  200/  800]\n",
      "loss: 0.056264  [  400/  800]\n",
      "loss: 0.055694  [  600/  800]\n",
      "Test Error: Loss = 0.112138 \n",
      "\n",
      "Epoch 42\n",
      "-------------------------------\n",
      "loss: 0.052962  [    0/  800]\n",
      "loss: 0.051727  [  200/  800]\n",
      "loss: 0.051939  [  400/  800]\n",
      "loss: 0.053841  [  600/  800]\n",
      "Test Error: Loss = 0.107495 \n",
      "\n",
      "Epoch 43\n",
      "-------------------------------\n",
      "loss: 0.051179  [    0/  800]\n",
      "loss: 0.051092  [  200/  800]\n",
      "loss: 0.050360  [  400/  800]\n",
      "loss: 0.053907  [  600/  800]\n",
      "Test Error: Loss = 0.103022 \n",
      "\n",
      "Epoch 44\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.052821  [    0/  800]\n",
      "loss: 0.051792  [  200/  800]\n",
      "loss: 0.053339  [  400/  800]\n",
      "loss: 0.049544  [  600/  800]\n",
      "Test Error: Loss = 0.109535 \n",
      "\n",
      "Epoch 45\n",
      "-------------------------------\n",
      "loss: 0.049332  [    0/  800]\n",
      "loss: 0.049622  [  200/  800]\n",
      "loss: 0.048183  [  400/  800]\n",
      "loss: 0.048775  [  600/  800]\n",
      "Test Error: Loss = 0.101895 \n",
      "\n",
      "Epoch 46\n",
      "-------------------------------\n",
      "loss: 0.053022  [    0/  800]\n",
      "loss: 0.046000  [  200/  800]\n",
      "loss: 0.048727  [  400/  800]\n",
      "loss: 0.044849  [  600/  800]\n",
      "Test Error: Loss = 0.102147 \n",
      "\n",
      "Epoch 47\n",
      "-------------------------------\n",
      "loss: 0.049187  [    0/  800]\n",
      "loss: 0.046869  [  200/  800]\n",
      "loss: 0.053718  [  400/  800]\n",
      "loss: 0.044268  [  600/  800]\n",
      "Test Error: Loss = 0.099968 \n",
      "\n",
      "Epoch 48\n",
      "-------------------------------\n",
      "loss: 0.049477  [    0/  800]\n",
      "loss: 0.048263  [  200/  800]\n",
      "loss: 0.049365  [  400/  800]\n",
      "loss: 0.048947  [  600/  800]\n",
      "Test Error: Loss = 0.104351 \n",
      "\n",
      "Epoch 49\n",
      "-------------------------------\n",
      "loss: 0.045838  [    0/  800]\n",
      "loss: 0.050439  [  200/  800]\n",
      "loss: 0.053536  [  400/  800]\n",
      "loss: 0.049026  [  600/  800]\n",
      "Test Error: Loss = 0.098442 \n",
      "\n",
      "Epoch 50\n",
      "-------------------------------\n",
      "loss: 0.043560  [    0/  800]\n",
      "loss: 0.049241  [  200/  800]\n",
      "loss: 0.045659  [  400/  800]\n",
      "loss: 0.049103  [  600/  800]\n",
      "Test Error: Loss = 0.097188 \n",
      "\n",
      "Epoch 51\n",
      "-------------------------------\n",
      "loss: 0.047036  [    0/  800]\n",
      "loss: 0.046435  [  200/  800]\n",
      "loss: 0.044052  [  400/  800]\n",
      "loss: 0.045393  [  600/  800]\n",
      "Test Error: Loss = 0.096907 \n",
      "\n",
      "Epoch 52\n",
      "-------------------------------\n",
      "loss: 0.038787  [    0/  800]\n",
      "loss: 0.046443  [  200/  800]\n",
      "loss: 0.045219  [  400/  800]\n",
      "loss: 0.048416  [  600/  800]\n",
      "Test Error: Loss = 0.094215 \n",
      "\n",
      "Epoch 53\n",
      "-------------------------------\n",
      "loss: 0.051179  [    0/  800]\n",
      "loss: 0.043608  [  200/  800]\n",
      "loss: 0.040230  [  400/  800]\n",
      "loss: 0.042359  [  600/  800]\n",
      "Test Error: Loss = 0.093319 \n",
      "\n",
      "Epoch 54\n",
      "-------------------------------\n",
      "loss: 0.042140  [    0/  800]\n",
      "loss: 0.041348  [  200/  800]\n",
      "loss: 0.043131  [  400/  800]\n",
      "loss: 0.045767  [  600/  800]\n",
      "Test Error: Loss = 0.094597 \n",
      "\n",
      "Epoch 55\n",
      "-------------------------------\n",
      "loss: 0.047071  [    0/  800]\n",
      "loss: 0.046291  [  200/  800]\n",
      "loss: 0.040459  [  400/  800]\n",
      "loss: 0.045012  [  600/  800]\n",
      "Test Error: Loss = 0.093543 \n",
      "\n",
      "Epoch 56\n",
      "-------------------------------\n",
      "loss: 0.045307  [    0/  800]\n",
      "loss: 0.044031  [  200/  800]\n",
      "loss: 0.046924  [  400/  800]\n",
      "loss: 0.042313  [  600/  800]\n",
      "Test Error: Loss = 0.092399 \n",
      "\n",
      "Epoch 57\n",
      "-------------------------------\n",
      "loss: 0.043717  [    0/  800]\n",
      "loss: 0.044216  [  200/  800]\n",
      "loss: 0.041123  [  400/  800]\n",
      "loss: 0.046481  [  600/  800]\n",
      "Test Error: Loss = 0.092515 \n",
      "\n",
      "Epoch 58\n",
      "-------------------------------\n",
      "loss: 0.043345  [    0/  800]\n",
      "loss: 0.044931  [  200/  800]\n",
      "loss: 0.043752  [  400/  800]\n",
      "loss: 0.042773  [  600/  800]\n",
      "Test Error: Loss = 0.092529 \n",
      "\n",
      "Epoch 59\n",
      "-------------------------------\n",
      "loss: 0.042313  [    0/  800]\n",
      "loss: 0.041359  [  200/  800]\n",
      "loss: 0.046913  [  400/  800]\n",
      "loss: 0.042402  [  600/  800]\n",
      "Test Error: Loss = 0.089875 \n",
      "\n",
      "Epoch 60\n",
      "-------------------------------\n",
      "loss: 0.038689  [    0/  800]\n",
      "loss: 0.045294  [  200/  800]\n",
      "loss: 0.037459  [  400/  800]\n",
      "loss: 0.039952  [  600/  800]\n",
      "Test Error: Loss = 0.090004 \n",
      "\n",
      "Epoch 61\n",
      "-------------------------------\n",
      "loss: 0.042445  [    0/  800]\n",
      "loss: 0.039704  [  200/  800]\n",
      "loss: 0.042975  [  400/  800]\n",
      "loss: 0.042969  [  600/  800]\n",
      "Test Error: Loss = 0.089849 \n",
      "\n",
      "Epoch 62\n",
      "-------------------------------\n",
      "loss: 0.042457  [    0/  800]\n",
      "loss: 0.039399  [  200/  800]\n",
      "loss: 0.043206  [  400/  800]\n",
      "loss: 0.043079  [  600/  800]\n",
      "Test Error: Loss = 0.092290 \n",
      "\n",
      "Epoch 63\n",
      "-------------------------------\n",
      "loss: 0.044771  [    0/  800]\n",
      "loss: 0.045756  [  200/  800]\n",
      "loss: 0.040764  [  400/  800]\n",
      "loss: 0.044976  [  600/  800]\n",
      "Test Error: Loss = 0.089528 \n",
      "\n",
      "Epoch 64\n",
      "-------------------------------\n",
      "loss: 0.039331  [    0/  800]\n",
      "loss: 0.044210  [  200/  800]\n",
      "loss: 0.045484  [  400/  800]\n",
      "loss: 0.037737  [  600/  800]\n",
      "Test Error: Loss = 0.089206 \n",
      "\n",
      "Epoch 65\n",
      "-------------------------------\n",
      "loss: 0.044862  [    0/  800]\n",
      "loss: 0.041412  [  200/  800]\n",
      "loss: 0.039404  [  400/  800]\n",
      "loss: 0.044880  [  600/  800]\n",
      "Test Error: Loss = 0.088489 \n",
      "\n",
      "Epoch 66\n",
      "-------------------------------\n",
      "loss: 0.040109  [    0/  800]\n",
      "loss: 0.044568  [  200/  800]\n",
      "loss: 0.044059  [  400/  800]\n",
      "loss: 0.041133  [  600/  800]\n",
      "Test Error: Loss = 0.089107 \n",
      "\n",
      "Epoch 67\n",
      "-------------------------------\n",
      "loss: 0.044216  [    0/  800]\n",
      "loss: 0.043362  [  200/  800]\n",
      "loss: 0.042107  [  400/  800]\n",
      "loss: 0.041288  [  600/  800]\n",
      "Test Error: Loss = 0.088962 \n",
      "\n",
      "Epoch 68\n",
      "-------------------------------\n",
      "loss: 0.045301  [    0/  800]\n",
      "loss: 0.043324  [  200/  800]\n",
      "loss: 0.041245  [  400/  800]\n",
      "loss: 0.037901  [  600/  800]\n",
      "Test Error: Loss = 0.088026 \n",
      "\n",
      "Epoch 69\n",
      "-------------------------------\n",
      "loss: 0.039066  [    0/  800]\n",
      "loss: 0.039397  [  200/  800]\n",
      "loss: 0.038343  [  400/  800]\n",
      "loss: 0.044432  [  600/  800]\n",
      "Test Error: Loss = 0.088344 \n",
      "\n",
      "Epoch 70\n",
      "-------------------------------\n",
      "loss: 0.043482  [    0/  800]\n",
      "loss: 0.042158  [  200/  800]\n",
      "loss: 0.038158  [  400/  800]\n",
      "loss: 0.040603  [  600/  800]\n",
      "Test Error: Loss = 0.088059 \n",
      "\n",
      "Epoch 71\n",
      "-------------------------------\n",
      "loss: 0.041697  [    0/  800]\n",
      "loss: 0.040441  [  200/  800]\n",
      "loss: 0.037566  [  400/  800]\n",
      "loss: 0.041711  [  600/  800]\n",
      "Test Error: Loss = 0.087026 \n",
      "\n",
      "Epoch 72\n",
      "-------------------------------\n",
      "loss: 0.039849  [    0/  800]\n",
      "loss: 0.036965  [  200/  800]\n",
      "loss: 0.043554  [  400/  800]\n",
      "loss: 0.044613  [  600/  800]\n",
      "Test Error: Loss = 0.090578 \n",
      "\n",
      "Epoch 73\n",
      "-------------------------------\n",
      "loss: 0.040362  [    0/  800]\n",
      "loss: 0.043863  [  200/  800]\n",
      "loss: 0.045122  [  400/  800]\n",
      "loss: 0.043468  [  600/  800]\n",
      "Test Error: Loss = 0.090028 \n",
      "\n",
      "Epoch 74\n",
      "-------------------------------\n",
      "loss: 0.041553  [    0/  800]\n",
      "loss: 0.041647  [  200/  800]\n",
      "loss: 0.045185  [  400/  800]\n",
      "loss: 0.045000  [  600/  800]\n",
      "Test Error: Loss = 0.088234 \n",
      "\n",
      "Epoch 75\n",
      "-------------------------------\n",
      "loss: 0.040417  [    0/  800]\n",
      "loss: 0.041021  [  200/  800]\n",
      "loss: 0.041077  [  400/  800]\n",
      "loss: 0.042566  [  600/  800]\n",
      "Test Error: Loss = 0.088095 \n",
      "\n",
      "Epoch 76\n",
      "-------------------------------\n",
      "loss: 0.036986  [    0/  800]\n",
      "loss: 0.041663  [  200/  800]\n",
      "loss: 0.041826  [  400/  800]\n",
      "loss: 0.044789  [  600/  800]\n",
      "Test Error: Loss = 0.090318 \n",
      "\n",
      "Epoch 77\n",
      "-------------------------------\n",
      "loss: 0.042885  [    0/  800]\n",
      "loss: 0.039863  [  200/  800]\n",
      "loss: 0.040400  [  400/  800]\n",
      "loss: 0.039892  [  600/  800]\n",
      "Test Error: Loss = 0.089451 \n",
      "\n",
      "Epoch 78\n",
      "-------------------------------\n",
      "loss: 0.043045  [    0/  800]\n",
      "loss: 0.038535  [  200/  800]\n",
      "loss: 0.041481  [  400/  800]\n",
      "loss: 0.040626  [  600/  800]\n",
      "Test Error: Loss = 0.088468 \n",
      "\n",
      "Epoch 79\n",
      "-------------------------------\n",
      "loss: 0.038047  [    0/  800]\n",
      "loss: 0.039059  [  200/  800]\n",
      "loss: 0.039842  [  400/  800]\n",
      "loss: 0.041244  [  600/  800]\n",
      "Test Error: Loss = 0.087660 \n",
      "\n",
      "Epoch 80\n",
      "-------------------------------\n",
      "loss: 0.038591  [    0/  800]\n",
      "loss: 0.043247  [  200/  800]\n",
      "loss: 0.040222  [  400/  800]\n",
      "loss: 0.035791  [  600/  800]\n",
      "Test Error: Loss = 0.087857 \n",
      "\n",
      "Epoch 81\n",
      "-------------------------------\n",
      "loss: 0.041245  [    0/  800]\n",
      "loss: 0.041729  [  200/  800]\n",
      "loss: 0.037857  [  400/  800]\n",
      "loss: 0.035422  [  600/  800]\n",
      "Test Error: Loss = 0.088652 \n",
      "\n",
      "Epoch 82\n",
      "-------------------------------\n",
      "loss: 0.040449  [    0/  800]\n",
      "loss: 0.039141  [  200/  800]\n",
      "loss: 0.037534  [  400/  800]\n",
      "loss: 0.036993  [  600/  800]\n",
      "Test Error: Loss = 0.087851 \n",
      "\n",
      "Epoch 83\n",
      "-------------------------------\n",
      "loss: 0.039411  [    0/  800]\n",
      "loss: 0.039387  [  200/  800]\n",
      "loss: 0.040105  [  400/  800]\n",
      "loss: 0.034658  [  600/  800]\n",
      "Test Error: Loss = 0.087364 \n",
      "\n",
      "Epoch 84\n",
      "-------------------------------\n",
      "loss: 0.038879  [    0/  800]\n",
      "loss: 0.038537  [  200/  800]\n",
      "loss: 0.042956  [  400/  800]\n",
      "loss: 0.038913  [  600/  800]\n",
      "Test Error: Loss = 0.091713 \n",
      "\n",
      "Epoch 85\n",
      "-------------------------------\n",
      "loss: 0.045853  [    0/  800]\n",
      "loss: 0.043539  [  200/  800]\n",
      "loss: 0.039682  [  400/  800]\n",
      "loss: 0.044687  [  600/  800]\n",
      "Test Error: Loss = 0.093087 \n",
      "\n",
      "Epoch 86\n",
      "-------------------------------\n",
      "loss: 0.042923  [    0/  800]\n",
      "loss: 0.040733  [  200/  800]\n",
      "loss: 0.042760  [  400/  800]\n",
      "loss: 0.038584  [  600/  800]\n",
      "Test Error: Loss = 0.091558 \n",
      "\n",
      "Epoch 87\n",
      "-------------------------------\n",
      "loss: 0.040841  [    0/  800]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.037911  [  200/  800]\n",
      "loss: 0.039692  [  400/  800]\n",
      "loss: 0.039440  [  600/  800]\n",
      "Test Error: Loss = 0.088878 \n",
      "\n",
      "Epoch 88\n",
      "-------------------------------\n",
      "loss: 0.037690  [    0/  800]\n",
      "loss: 0.036846  [  200/  800]\n",
      "loss: 0.044249  [  400/  800]\n",
      "loss: 0.043115  [  600/  800]\n",
      "Test Error: Loss = 0.088770 \n",
      "\n",
      "Epoch 89\n",
      "-------------------------------\n",
      "loss: 0.042504  [    0/  800]\n",
      "loss: 0.039700  [  200/  800]\n",
      "loss: 0.039556  [  400/  800]\n",
      "loss: 0.040995  [  600/  800]\n",
      "Test Error: Loss = 0.090041 \n",
      "\n",
      "Epoch 90\n",
      "-------------------------------\n",
      "loss: 0.038563  [    0/  800]\n",
      "loss: 0.035925  [  200/  800]\n",
      "loss: 0.042462  [  400/  800]\n",
      "loss: 0.036571  [  600/  800]\n",
      "Test Error: Loss = 0.084786 \n",
      "\n",
      "Epoch 91\n",
      "-------------------------------\n",
      "loss: 0.039474  [    0/  800]\n",
      "loss: 0.036911  [  200/  800]\n",
      "loss: 0.038549  [  400/  800]\n",
      "loss: 0.035327  [  600/  800]\n",
      "Test Error: Loss = 0.089809 \n",
      "\n",
      "Epoch 92\n",
      "-------------------------------\n",
      "loss: 0.040751  [    0/  800]\n",
      "loss: 0.035931  [  200/  800]\n",
      "loss: 0.036086  [  400/  800]\n",
      "loss: 0.041151  [  600/  800]\n",
      "Test Error: Loss = 0.084710 \n",
      "\n",
      "Epoch 93\n",
      "-------------------------------\n",
      "loss: 0.033174  [    0/  800]\n",
      "loss: 0.043163  [  200/  800]\n",
      "loss: 0.031663  [  400/  800]\n",
      "loss: 0.036365  [  600/  800]\n",
      "Test Error: Loss = 0.086414 \n",
      "\n",
      "Epoch 94\n",
      "-------------------------------\n",
      "loss: 0.031882  [    0/  800]\n",
      "loss: 0.037027  [  200/  800]\n",
      "loss: 0.038660  [  400/  800]\n",
      "loss: 0.039823  [  600/  800]\n",
      "Test Error: Loss = 0.085032 \n",
      "\n",
      "Epoch 95\n",
      "-------------------------------\n",
      "loss: 0.033003  [    0/  800]\n",
      "loss: 0.039635  [  200/  800]\n",
      "loss: 0.043553  [  400/  800]\n",
      "loss: 0.036841  [  600/  800]\n",
      "Test Error: Loss = 0.092721 \n",
      "\n",
      "Epoch 96\n",
      "-------------------------------\n",
      "loss: 0.032676  [    0/  800]\n",
      "loss: 0.035822  [  200/  800]\n",
      "loss: 0.039956  [  400/  800]\n",
      "loss: 0.040338  [  600/  800]\n",
      "Test Error: Loss = 0.087174 \n",
      "\n",
      "Epoch 97\n",
      "-------------------------------\n",
      "loss: 0.033111  [    0/  800]\n",
      "loss: 0.037005  [  200/  800]\n",
      "loss: 0.043865  [  400/  800]\n",
      "loss: 0.040426  [  600/  800]\n",
      "Test Error: Loss = 0.088331 \n",
      "\n",
      "Epoch 98\n",
      "-------------------------------\n",
      "loss: 0.039642  [    0/  800]\n",
      "loss: 0.035362  [  200/  800]\n",
      "loss: 0.036004  [  400/  800]\n",
      "loss: 0.042284  [  600/  800]\n",
      "Test Error: Loss = 0.082272 \n",
      "\n",
      "Epoch 99\n",
      "-------------------------------\n",
      "loss: 0.034383  [    0/  800]\n",
      "loss: 0.035496  [  200/  800]\n",
      "loss: 0.037399  [  400/  800]\n",
      "loss: 0.035412  [  600/  800]\n",
      "Test Error: Loss = 0.084564 \n",
      "\n",
      "Epoch 100\n",
      "-------------------------------\n",
      "loss: 0.036652  [    0/  800]\n",
      "loss: 0.037816  [  200/  800]\n",
      "loss: 0.029504  [  400/  800]\n",
      "loss: 0.037963  [  600/  800]\n",
      "Test Error: Loss = 0.081408 \n",
      "\n",
      "Epoch 101\n",
      "-------------------------------\n",
      "loss: 0.033897  [    0/  800]\n",
      "loss: 0.031543  [  200/  800]\n",
      "loss: 0.036756  [  400/  800]\n",
      "loss: 0.029549  [  600/  800]\n",
      "Test Error: Loss = 0.083094 \n",
      "\n",
      "Epoch 102\n",
      "-------------------------------\n",
      "loss: 0.031524  [    0/  800]\n",
      "loss: 0.035906  [  200/  800]\n",
      "loss: 0.033893  [  400/  800]\n",
      "loss: 0.031199  [  600/  800]\n",
      "Test Error: Loss = 0.081249 \n",
      "\n",
      "Epoch 103\n",
      "-------------------------------\n",
      "loss: 0.030147  [    0/  800]\n",
      "loss: 0.036885  [  200/  800]\n",
      "loss: 0.034099  [  400/  800]\n",
      "loss: 0.031756  [  600/  800]\n",
      "Test Error: Loss = 0.079914 \n",
      "\n",
      "Epoch 104\n",
      "-------------------------------\n",
      "loss: 0.031423  [    0/  800]\n",
      "loss: 0.033210  [  200/  800]\n",
      "loss: 0.030584  [  400/  800]\n",
      "loss: 0.039245  [  600/  800]\n",
      "Test Error: Loss = 0.081864 \n",
      "\n",
      "Epoch 105\n",
      "-------------------------------\n",
      "loss: 0.037334  [    0/  800]\n",
      "loss: 0.031390  [  200/  800]\n",
      "loss: 0.036022  [  400/  800]\n",
      "loss: 0.033942  [  600/  800]\n",
      "Test Error: Loss = 0.077832 \n",
      "\n",
      "Epoch 106\n",
      "-------------------------------\n",
      "loss: 0.030747  [    0/  800]\n",
      "loss: 0.033370  [  200/  800]\n",
      "loss: 0.032154  [  400/  800]\n",
      "loss: 0.034208  [  600/  800]\n",
      "Test Error: Loss = 0.081088 \n",
      "\n",
      "Epoch 107\n",
      "-------------------------------\n",
      "loss: 0.031279  [    0/  800]\n",
      "loss: 0.035389  [  200/  800]\n",
      "loss: 0.034697  [  400/  800]\n",
      "loss: 0.034081  [  600/  800]\n",
      "Test Error: Loss = 0.077549 \n",
      "\n",
      "Epoch 108\n",
      "-------------------------------\n",
      "loss: 0.028388  [    0/  800]\n",
      "loss: 0.031770  [  200/  800]\n",
      "loss: 0.031863  [  400/  800]\n",
      "loss: 0.033562  [  600/  800]\n",
      "Test Error: Loss = 0.080321 \n",
      "\n",
      "Epoch 109\n",
      "-------------------------------\n",
      "loss: 0.030613  [    0/  800]\n",
      "loss: 0.031505  [  200/  800]\n",
      "loss: 0.029378  [  400/  800]\n",
      "loss: 0.030519  [  600/  800]\n",
      "Test Error: Loss = 0.080404 \n",
      "\n",
      "Epoch 110\n",
      "-------------------------------\n",
      "loss: 0.029772  [    0/  800]\n",
      "loss: 0.031790  [  200/  800]\n",
      "loss: 0.032409  [  400/  800]\n",
      "loss: 0.031739  [  600/  800]\n",
      "Test Error: Loss = 0.081841 \n",
      "\n",
      "Epoch 111\n",
      "-------------------------------\n",
      "loss: 0.031804  [    0/  800]\n",
      "loss: 0.031193  [  200/  800]\n",
      "loss: 0.031166  [  400/  800]\n",
      "loss: 0.032772  [  600/  800]\n",
      "Test Error: Loss = 0.073574 \n",
      "\n",
      "Epoch 112\n",
      "-------------------------------\n",
      "loss: 0.030866  [    0/  800]\n",
      "loss: 0.027535  [  200/  800]\n",
      "loss: 0.029107  [  400/  800]\n",
      "loss: 0.030114  [  600/  800]\n",
      "Test Error: Loss = 0.072652 \n",
      "\n",
      "Epoch 113\n",
      "-------------------------------\n",
      "loss: 0.027384  [    0/  800]\n",
      "loss: 0.028280  [  200/  800]\n",
      "loss: 0.029498  [  400/  800]\n",
      "loss: 0.028913  [  600/  800]\n",
      "Test Error: Loss = 0.073369 \n",
      "\n",
      "Epoch 114\n",
      "-------------------------------\n",
      "loss: 0.028082  [    0/  800]\n",
      "loss: 0.030262  [  200/  800]\n",
      "loss: 0.028827  [  400/  800]\n",
      "loss: 0.031675  [  600/  800]\n",
      "Test Error: Loss = 0.079106 \n",
      "\n",
      "Epoch 115\n",
      "-------------------------------\n",
      "loss: 0.026655  [    0/  800]\n",
      "loss: 0.030183  [  200/  800]\n",
      "loss: 0.031938  [  400/  800]\n",
      "loss: 0.029012  [  600/  800]\n",
      "Test Error: Loss = 0.076137 \n",
      "\n",
      "Epoch 116\n",
      "-------------------------------\n",
      "loss: 0.029660  [    0/  800]\n",
      "loss: 0.029291  [  200/  800]\n",
      "loss: 0.028596  [  400/  800]\n",
      "loss: 0.029075  [  600/  800]\n",
      "Test Error: Loss = 0.076443 \n",
      "\n",
      "Epoch 117\n",
      "-------------------------------\n",
      "loss: 0.028178  [    0/  800]\n",
      "loss: 0.025578  [  200/  800]\n",
      "loss: 0.029515  [  400/  800]\n",
      "loss: 0.028784  [  600/  800]\n",
      "Test Error: Loss = 0.072337 \n",
      "\n",
      "Epoch 118\n",
      "-------------------------------\n",
      "loss: 0.029999  [    0/  800]\n",
      "loss: 0.029158  [  200/  800]\n",
      "loss: 0.029645  [  400/  800]\n",
      "loss: 0.030325  [  600/  800]\n",
      "Test Error: Loss = 0.074846 \n",
      "\n",
      "Epoch 119\n",
      "-------------------------------\n",
      "loss: 0.027824  [    0/  800]\n",
      "loss: 0.030631  [  200/  800]\n",
      "loss: 0.025506  [  400/  800]\n",
      "loss: 0.028095  [  600/  800]\n",
      "Test Error: Loss = 0.073850 \n",
      "\n",
      "Epoch 120\n",
      "-------------------------------\n",
      "loss: 0.029115  [    0/  800]\n",
      "loss: 0.027488  [  200/  800]\n",
      "loss: 0.028270  [  400/  800]\n",
      "loss: 0.030338  [  600/  800]\n",
      "Test Error: Loss = 0.075721 \n",
      "\n",
      "Epoch 121\n",
      "-------------------------------\n",
      "loss: 0.032310  [    0/  800]\n",
      "loss: 0.030350  [  200/  800]\n",
      "loss: 0.028089  [  400/  800]\n",
      "loss: 0.029706  [  600/  800]\n",
      "Test Error: Loss = 0.076046 \n",
      "\n",
      "Epoch 122\n",
      "-------------------------------\n",
      "loss: 0.027436  [    0/  800]\n",
      "loss: 0.034862  [  200/  800]\n",
      "loss: 0.031981  [  400/  800]\n",
      "loss: 0.037567  [  600/  800]\n",
      "Test Error: Loss = 0.085206 \n",
      "\n",
      "Epoch 123\n",
      "-------------------------------\n",
      "loss: 0.032459  [    0/  800]\n",
      "loss: 0.027629  [  200/  800]\n",
      "loss: 0.030744  [  400/  800]\n",
      "loss: 0.031506  [  600/  800]\n",
      "Test Error: Loss = 0.083305 \n",
      "\n",
      "Epoch 124\n",
      "-------------------------------\n",
      "loss: 0.028789  [    0/  800]\n",
      "loss: 0.030719  [  200/  800]\n",
      "loss: 0.028931  [  400/  800]\n",
      "loss: 0.031095  [  600/  800]\n",
      "Test Error: Loss = 0.075171 \n",
      "\n",
      "Epoch 125\n",
      "-------------------------------\n",
      "loss: 0.029693  [    0/  800]\n",
      "loss: 0.030640  [  200/  800]\n",
      "loss: 0.027278  [  400/  800]\n",
      "loss: 0.022325  [  600/  800]\n",
      "Test Error: Loss = 0.074503 \n",
      "\n",
      "Epoch 126\n",
      "-------------------------------\n",
      "loss: 0.028052  [    0/  800]\n",
      "loss: 0.025504  [  200/  800]\n",
      "loss: 0.028533  [  400/  800]\n",
      "loss: 0.030256  [  600/  800]\n",
      "Test Error: Loss = 0.075155 \n",
      "\n",
      "Epoch 127\n",
      "-------------------------------\n",
      "loss: 0.024128  [    0/  800]\n",
      "loss: 0.028026  [  200/  800]\n",
      "loss: 0.025046  [  400/  800]\n",
      "loss: 0.030418  [  600/  800]\n",
      "Test Error: Loss = 0.072308 \n",
      "\n",
      "Epoch 128\n",
      "-------------------------------\n",
      "loss: 0.026181  [    0/  800]\n",
      "loss: 0.022887  [  200/  800]\n",
      "loss: 0.026290  [  400/  800]\n",
      "loss: 0.030208  [  600/  800]\n",
      "Test Error: Loss = 0.072506 \n",
      "\n",
      "Epoch 129\n",
      "-------------------------------\n",
      "loss: 0.028615  [    0/  800]\n",
      "loss: 0.027245  [  200/  800]\n",
      "loss: 0.027014  [  400/  800]\n",
      "loss: 0.028149  [  600/  800]\n",
      "Test Error: Loss = 0.075161 \n",
      "\n",
      "Epoch 130\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.027055  [    0/  800]\n",
      "loss: 0.025211  [  200/  800]\n",
      "loss: 0.028537  [  400/  800]\n",
      "loss: 0.026811  [  600/  800]\n",
      "Test Error: Loss = 0.070674 \n",
      "\n",
      "Epoch 131\n",
      "-------------------------------\n",
      "loss: 0.026960  [    0/  800]\n",
      "loss: 0.026012  [  200/  800]\n",
      "loss: 0.024846  [  400/  800]\n",
      "loss: 0.026467  [  600/  800]\n",
      "Test Error: Loss = 0.071145 \n",
      "\n",
      "Epoch 132\n",
      "-------------------------------\n",
      "loss: 0.026434  [    0/  800]\n",
      "loss: 0.027344  [  200/  800]\n",
      "loss: 0.026109  [  400/  800]\n",
      "loss: 0.026685  [  600/  800]\n",
      "Test Error: Loss = 0.070328 \n",
      "\n",
      "Epoch 133\n",
      "-------------------------------\n",
      "loss: 0.027894  [    0/  800]\n",
      "loss: 0.026446  [  200/  800]\n",
      "loss: 0.029560  [  400/  800]\n",
      "loss: 0.022219  [  600/  800]\n",
      "Test Error: Loss = 0.075123 \n",
      "\n",
      "Epoch 134\n",
      "-------------------------------\n",
      "loss: 0.028991  [    0/  800]\n",
      "loss: 0.025465  [  200/  800]\n",
      "loss: 0.026994  [  400/  800]\n",
      "loss: 0.024497  [  600/  800]\n",
      "Test Error: Loss = 0.071920 \n",
      "\n",
      "Epoch 135\n",
      "-------------------------------\n",
      "loss: 0.023414  [    0/  800]\n",
      "loss: 0.022299  [  200/  800]\n",
      "loss: 0.022639  [  400/  800]\n",
      "loss: 0.026935  [  600/  800]\n",
      "Test Error: Loss = 0.072865 \n",
      "\n",
      "Epoch 136\n",
      "-------------------------------\n",
      "loss: 0.024394  [    0/  800]\n",
      "loss: 0.024682  [  200/  800]\n",
      "loss: 0.024047  [  400/  800]\n",
      "loss: 0.025750  [  600/  800]\n",
      "Test Error: Loss = 0.082483 \n",
      "\n",
      "Epoch 137\n",
      "-------------------------------\n",
      "loss: 0.031863  [    0/  800]\n",
      "loss: 0.026377  [  200/  800]\n",
      "loss: 0.026649  [  400/  800]\n",
      "loss: 0.026363  [  600/  800]\n",
      "Test Error: Loss = 0.079532 \n",
      "\n",
      "Epoch 138\n",
      "-------------------------------\n",
      "loss: 0.029444  [    0/  800]\n",
      "loss: 0.026693  [  200/  800]\n",
      "loss: 0.023706  [  400/  800]\n",
      "loss: 0.024432  [  600/  800]\n",
      "Test Error: Loss = 0.075854 \n",
      "\n",
      "Epoch 139\n",
      "-------------------------------\n",
      "loss: 0.023492  [    0/  800]\n",
      "loss: 0.025002  [  200/  800]\n",
      "loss: 0.027445  [  400/  800]\n",
      "loss: 0.023875  [  600/  800]\n",
      "Test Error: Loss = 0.074219 \n",
      "\n",
      "Epoch 140\n",
      "-------------------------------\n",
      "loss: 0.024453  [    0/  800]\n",
      "loss: 0.027273  [  200/  800]\n",
      "loss: 0.025036  [  400/  800]\n",
      "loss: 0.025097  [  600/  800]\n",
      "Test Error: Loss = 0.075398 \n",
      "\n",
      "Epoch 141\n",
      "-------------------------------\n",
      "loss: 0.027980  [    0/  800]\n",
      "loss: 0.025499  [  200/  800]\n",
      "loss: 0.021985  [  400/  800]\n",
      "loss: 0.027307  [  600/  800]\n",
      "Test Error: Loss = 0.071970 \n",
      "\n",
      "Epoch 142\n",
      "-------------------------------\n",
      "loss: 0.024705  [    0/  800]\n",
      "loss: 0.023749  [  200/  800]\n",
      "loss: 0.022765  [  400/  800]\n",
      "loss: 0.027626  [  600/  800]\n",
      "Test Error: Loss = 0.073472 \n",
      "\n",
      "Epoch 143\n",
      "-------------------------------\n",
      "loss: 0.023118  [    0/  800]\n",
      "loss: 0.023488  [  200/  800]\n",
      "loss: 0.028845  [  400/  800]\n",
      "loss: 0.027678  [  600/  800]\n",
      "Test Error: Loss = 0.080081 \n",
      "\n",
      "Epoch 144\n",
      "-------------------------------\n",
      "loss: 0.024888  [    0/  800]\n",
      "loss: 0.029795  [  200/  800]\n",
      "loss: 0.028347  [  400/  800]\n",
      "loss: 0.025370  [  600/  800]\n",
      "Test Error: Loss = 0.076976 \n",
      "\n",
      "Epoch 145\n",
      "-------------------------------\n",
      "loss: 0.023457  [    0/  800]\n",
      "loss: 0.026466  [  200/  800]\n",
      "loss: 0.026940  [  400/  800]\n",
      "loss: 0.024525  [  600/  800]\n",
      "Test Error: Loss = 0.075906 \n",
      "\n",
      "Epoch 146\n",
      "-------------------------------\n",
      "loss: 0.023094  [    0/  800]\n",
      "loss: 0.024454  [  200/  800]\n",
      "loss: 0.024104  [  400/  800]\n",
      "loss: 0.028294  [  600/  800]\n",
      "Test Error: Loss = 0.073190 \n",
      "\n",
      "Epoch 147\n",
      "-------------------------------\n",
      "loss: 0.024524  [    0/  800]\n",
      "loss: 0.023569  [  200/  800]\n",
      "loss: 0.025948  [  400/  800]\n",
      "loss: 0.024916  [  600/  800]\n",
      "Test Error: Loss = 0.076032 \n",
      "\n",
      "Epoch 148\n",
      "-------------------------------\n",
      "loss: 0.024648  [    0/  800]\n",
      "loss: 0.024655  [  200/  800]\n",
      "loss: 0.023737  [  400/  800]\n",
      "loss: 0.024848  [  600/  800]\n",
      "Test Error: Loss = 0.077552 \n",
      "\n",
      "Epoch 149\n",
      "-------------------------------\n",
      "loss: 0.023413  [    0/  800]\n",
      "loss: 0.023765  [  200/  800]\n",
      "loss: 0.025481  [  400/  800]\n",
      "loss: 0.023565  [  600/  800]\n",
      "Test Error: Loss = 0.079692 \n",
      "\n",
      "Epoch 150\n",
      "-------------------------------\n",
      "loss: 0.027288  [    0/  800]\n",
      "loss: 0.028368  [  200/  800]\n",
      "loss: 0.027451  [  400/  800]\n",
      "loss: 0.021611  [  600/  800]\n",
      "Test Error: Loss = 0.074391 \n",
      "\n",
      "Epoch 151\n",
      "-------------------------------\n",
      "loss: 0.024183  [    0/  800]\n",
      "loss: 0.025181  [  200/  800]\n",
      "loss: 0.027030  [  400/  800]\n",
      "loss: 0.025550  [  600/  800]\n",
      "Test Error: Loss = 0.074296 \n",
      "\n",
      "Epoch 152\n",
      "-------------------------------\n",
      "loss: 0.025883  [    0/  800]\n",
      "loss: 0.023627  [  200/  800]\n",
      "loss: 0.024386  [  400/  800]\n",
      "loss: 0.024096  [  600/  800]\n",
      "Test Error: Loss = 0.074815 \n",
      "\n",
      "Epoch 153\n",
      "-------------------------------\n",
      "loss: 0.020997  [    0/  800]\n",
      "loss: 0.022012  [  200/  800]\n",
      "loss: 0.022330  [  400/  800]\n",
      "loss: 0.025595  [  600/  800]\n",
      "Test Error: Loss = 0.075207 \n",
      "\n",
      "Epoch 154\n",
      "-------------------------------\n",
      "loss: 0.021566  [    0/  800]\n",
      "loss: 0.022811  [  200/  800]\n",
      "loss: 0.024564  [  400/  800]\n",
      "loss: 0.023829  [  600/  800]\n",
      "Test Error: Loss = 0.072686 \n",
      "\n",
      "Epoch 155\n",
      "-------------------------------\n",
      "loss: 0.021870  [    0/  800]\n",
      "loss: 0.021058  [  200/  800]\n",
      "loss: 0.025041  [  400/  800]\n",
      "loss: 0.026402  [  600/  800]\n",
      "Test Error: Loss = 0.074345 \n",
      "\n",
      "Epoch 156\n",
      "-------------------------------\n",
      "loss: 0.021859  [    0/  800]\n",
      "loss: 0.023773  [  200/  800]\n",
      "loss: 0.025482  [  400/  800]\n",
      "loss: 0.023946  [  600/  800]\n",
      "Test Error: Loss = 0.076282 \n",
      "\n",
      "Epoch 157\n",
      "-------------------------------\n",
      "loss: 0.023928  [    0/  800]\n",
      "loss: 0.024637  [  200/  800]\n",
      "loss: 0.025280  [  400/  800]\n",
      "loss: 0.021910  [  600/  800]\n",
      "Test Error: Loss = 0.072719 \n",
      "\n",
      "Epoch 158\n",
      "-------------------------------\n",
      "loss: 0.021644  [    0/  800]\n",
      "loss: 0.020624  [  200/  800]\n",
      "loss: 0.028488  [  400/  800]\n",
      "loss: 0.024065  [  600/  800]\n",
      "Test Error: Loss = 0.074893 \n",
      "\n",
      "Epoch 159\n",
      "-------------------------------\n",
      "loss: 0.023142  [    0/  800]\n",
      "loss: 0.020343  [  200/  800]\n",
      "loss: 0.021149  [  400/  800]\n",
      "loss: 0.021775  [  600/  800]\n",
      "Test Error: Loss = 0.072285 \n",
      "\n",
      "Epoch 160\n",
      "-------------------------------\n",
      "loss: 0.019836  [    0/  800]\n",
      "loss: 0.023021  [  200/  800]\n",
      "loss: 0.022128  [  400/  800]\n",
      "loss: 0.027397  [  600/  800]\n",
      "Test Error: Loss = 0.078817 \n",
      "\n",
      "Epoch 161\n",
      "-------------------------------\n",
      "loss: 0.021732  [    0/  800]\n",
      "loss: 0.027233  [  200/  800]\n",
      "loss: 0.025188  [  400/  800]\n",
      "loss: 0.026294  [  600/  800]\n",
      "Test Error: Loss = 0.081466 \n",
      "\n",
      "Epoch 162\n",
      "-------------------------------\n",
      "loss: 0.023110  [    0/  800]\n",
      "loss: 0.023853  [  200/  800]\n",
      "loss: 0.023021  [  400/  800]\n",
      "loss: 0.025612  [  600/  800]\n",
      "Test Error: Loss = 0.076394 \n",
      "\n",
      "Epoch 163\n",
      "-------------------------------\n",
      "loss: 0.021267  [    0/  800]\n",
      "loss: 0.021676  [  200/  800]\n",
      "loss: 0.021526  [  400/  800]\n",
      "loss: 0.023625  [  600/  800]\n",
      "Test Error: Loss = 0.071651 \n",
      "\n",
      "Epoch 164\n",
      "-------------------------------\n",
      "loss: 0.020537  [    0/  800]\n",
      "loss: 0.019857  [  200/  800]\n",
      "loss: 0.026316  [  400/  800]\n",
      "loss: 0.023272  [  600/  800]\n",
      "Test Error: Loss = 0.076560 \n",
      "\n",
      "Epoch 165\n",
      "-------------------------------\n",
      "loss: 0.023564  [    0/  800]\n",
      "loss: 0.023125  [  200/  800]\n",
      "loss: 0.024316  [  400/  800]\n",
      "loss: 0.022263  [  600/  800]\n",
      "Test Error: Loss = 0.076039 \n",
      "\n",
      "Epoch 166\n",
      "-------------------------------\n",
      "loss: 0.022073  [    0/  800]\n",
      "loss: 0.020981  [  200/  800]\n",
      "loss: 0.018493  [  400/  800]\n",
      "loss: 0.024689  [  600/  800]\n",
      "Test Error: Loss = 0.070089 \n",
      "\n",
      "Epoch 167\n",
      "-------------------------------\n",
      "loss: 0.018407  [    0/  800]\n",
      "loss: 0.022459  [  200/  800]\n",
      "loss: 0.018687  [  400/  800]\n",
      "loss: 0.018245  [  600/  800]\n",
      "Test Error: Loss = 0.068990 \n",
      "\n",
      "Epoch 168\n",
      "-------------------------------\n",
      "loss: 0.017120  [    0/  800]\n",
      "loss: 0.021286  [  200/  800]\n",
      "loss: 0.018943  [  400/  800]\n",
      "loss: 0.019540  [  600/  800]\n",
      "Test Error: Loss = 0.067972 \n",
      "\n",
      "Epoch 169\n",
      "-------------------------------\n",
      "loss: 0.017695  [    0/  800]\n",
      "loss: 0.022123  [  200/  800]\n",
      "loss: 0.017993  [  400/  800]\n",
      "loss: 0.019940  [  600/  800]\n",
      "Test Error: Loss = 0.071208 \n",
      "\n",
      "Epoch 170\n",
      "-------------------------------\n",
      "loss: 0.021366  [    0/  800]\n",
      "loss: 0.018289  [  200/  800]\n",
      "loss: 0.018357  [  400/  800]\n",
      "loss: 0.019504  [  600/  800]\n",
      "Test Error: Loss = 0.066729 \n",
      "\n",
      "Epoch 171\n",
      "-------------------------------\n",
      "loss: 0.021469  [    0/  800]\n",
      "loss: 0.020959  [  200/  800]\n",
      "loss: 0.021115  [  400/  800]\n",
      "loss: 0.018683  [  600/  800]\n",
      "Test Error: Loss = 0.066511 \n",
      "\n",
      "Epoch 172\n",
      "-------------------------------\n",
      "loss: 0.019024  [    0/  800]\n",
      "loss: 0.019192  [  200/  800]\n",
      "loss: 0.018683  [  400/  800]\n",
      "loss: 0.023955  [  600/  800]\n",
      "Test Error: Loss = 0.070491 \n",
      "\n",
      "Epoch 173\n",
      "-------------------------------\n",
      "loss: 0.018976  [    0/  800]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.019003  [  200/  800]\n",
      "loss: 0.021478  [  400/  800]\n",
      "loss: 0.019744  [  600/  800]\n",
      "Test Error: Loss = 0.067957 \n",
      "\n",
      "Epoch 174\n",
      "-------------------------------\n",
      "loss: 0.020917  [    0/  800]\n",
      "loss: 0.017635  [  200/  800]\n",
      "loss: 0.021313  [  400/  800]\n",
      "loss: 0.016984  [  600/  800]\n",
      "Test Error: Loss = 0.066979 \n",
      "\n",
      "Epoch 175\n",
      "-------------------------------\n",
      "loss: 0.016471  [    0/  800]\n",
      "loss: 0.019733  [  200/  800]\n",
      "loss: 0.019047  [  400/  800]\n",
      "loss: 0.021726  [  600/  800]\n",
      "Test Error: Loss = 0.069178 \n",
      "\n",
      "Epoch 176\n",
      "-------------------------------\n",
      "loss: 0.018385  [    0/  800]\n",
      "loss: 0.019585  [  200/  800]\n",
      "loss: 0.028125  [  400/  800]\n",
      "loss: 0.021698  [  600/  800]\n",
      "Test Error: Loss = 0.069225 \n",
      "\n",
      "Epoch 177\n",
      "-------------------------------\n",
      "loss: 0.020339  [    0/  800]\n",
      "loss: 0.020616  [  200/  800]\n",
      "loss: 0.018705  [  400/  800]\n",
      "loss: 0.019409  [  600/  800]\n",
      "Test Error: Loss = 0.064639 \n",
      "\n",
      "Epoch 178\n",
      "-------------------------------\n",
      "loss: 0.021848  [    0/  800]\n",
      "loss: 0.017761  [  200/  800]\n",
      "loss: 0.017397  [  400/  800]\n",
      "loss: 0.021381  [  600/  800]\n",
      "Test Error: Loss = 0.065599 \n",
      "\n",
      "Epoch 179\n",
      "-------------------------------\n",
      "loss: 0.018857  [    0/  800]\n",
      "loss: 0.019690  [  200/  800]\n",
      "loss: 0.015220  [  400/  800]\n",
      "loss: 0.015921  [  600/  800]\n",
      "Test Error: Loss = 0.059463 \n",
      "\n",
      "Epoch 180\n",
      "-------------------------------\n",
      "loss: 0.016001  [    0/  800]\n",
      "loss: 0.016214  [  200/  800]\n",
      "loss: 0.018581  [  400/  800]\n",
      "loss: 0.016690  [  600/  800]\n",
      "Test Error: Loss = 0.059197 \n",
      "\n",
      "Epoch 181\n",
      "-------------------------------\n",
      "loss: 0.015873  [    0/  800]\n",
      "loss: 0.013585  [  200/  800]\n",
      "loss: 0.015017  [  400/  800]\n",
      "loss: 0.014552  [  600/  800]\n",
      "Test Error: Loss = 0.064071 \n",
      "\n",
      "Epoch 182\n",
      "-------------------------------\n",
      "loss: 0.016944  [    0/  800]\n",
      "loss: 0.018312  [  200/  800]\n",
      "loss: 0.017385  [  400/  800]\n",
      "loss: 0.017358  [  600/  800]\n",
      "Test Error: Loss = 0.060558 \n",
      "\n",
      "Epoch 183\n",
      "-------------------------------\n",
      "loss: 0.015147  [    0/  800]\n",
      "loss: 0.015767  [  200/  800]\n",
      "loss: 0.017299  [  400/  800]\n",
      "loss: 0.017056  [  600/  800]\n",
      "Test Error: Loss = 0.061875 \n",
      "\n",
      "Epoch 184\n",
      "-------------------------------\n",
      "loss: 0.015453  [    0/  800]\n",
      "loss: 0.013801  [  200/  800]\n",
      "loss: 0.015063  [  400/  800]\n",
      "loss: 0.015539  [  600/  800]\n",
      "Test Error: Loss = 0.064954 \n",
      "\n",
      "Epoch 185\n",
      "-------------------------------\n",
      "loss: 0.017024  [    0/  800]\n",
      "loss: 0.015455  [  200/  800]\n",
      "loss: 0.016698  [  400/  800]\n",
      "loss: 0.016270  [  600/  800]\n",
      "Test Error: Loss = 0.060611 \n",
      "\n",
      "Epoch 186\n",
      "-------------------------------\n",
      "loss: 0.014700  [    0/  800]\n",
      "loss: 0.014785  [  200/  800]\n",
      "loss: 0.018411  [  400/  800]\n",
      "loss: 0.019112  [  600/  800]\n",
      "Test Error: Loss = 0.067584 \n",
      "\n",
      "Epoch 187\n",
      "-------------------------------\n",
      "loss: 0.019203  [    0/  800]\n",
      "loss: 0.019338  [  200/  800]\n",
      "loss: 0.016619  [  400/  800]\n",
      "loss: 0.019434  [  600/  800]\n",
      "Test Error: Loss = 0.064338 \n",
      "\n",
      "Epoch 188\n",
      "-------------------------------\n",
      "loss: 0.020164  [    0/  800]\n",
      "loss: 0.019497  [  200/  800]\n",
      "loss: 0.018512  [  400/  800]\n",
      "loss: 0.019526  [  600/  800]\n",
      "Test Error: Loss = 0.066560 \n",
      "\n",
      "Epoch 189\n",
      "-------------------------------\n",
      "loss: 0.017190  [    0/  800]\n",
      "loss: 0.019980  [  200/  800]\n",
      "loss: 0.014359  [  400/  800]\n",
      "loss: 0.014388  [  600/  800]\n",
      "Test Error: Loss = 0.061704 \n",
      "\n",
      "Epoch 190\n",
      "-------------------------------\n",
      "loss: 0.015333  [    0/  800]\n",
      "loss: 0.019045  [  200/  800]\n",
      "loss: 0.014743  [  400/  800]\n",
      "loss: 0.015713  [  600/  800]\n",
      "Test Error: Loss = 0.058213 \n",
      "\n",
      "Epoch 191\n",
      "-------------------------------\n",
      "loss: 0.014135  [    0/  800]\n",
      "loss: 0.012470  [  200/  800]\n",
      "loss: 0.018019  [  400/  800]\n",
      "loss: 0.016419  [  600/  800]\n",
      "Test Error: Loss = 0.062876 \n",
      "\n",
      "Epoch 192\n",
      "-------------------------------\n",
      "loss: 0.014448  [    0/  800]\n",
      "loss: 0.015978  [  200/  800]\n",
      "loss: 0.015536  [  400/  800]\n",
      "loss: 0.015182  [  600/  800]\n",
      "Test Error: Loss = 0.057615 \n",
      "\n",
      "Epoch 193\n",
      "-------------------------------\n",
      "loss: 0.012534  [    0/  800]\n",
      "loss: 0.016067  [  200/  800]\n",
      "loss: 0.017204  [  400/  800]\n",
      "loss: 0.013998  [  600/  800]\n",
      "Test Error: Loss = 0.058606 \n",
      "\n",
      "Epoch 194\n",
      "-------------------------------\n",
      "loss: 0.017159  [    0/  800]\n",
      "loss: 0.014660  [  200/  800]\n",
      "loss: 0.014782  [  400/  800]\n",
      "loss: 0.018398  [  600/  800]\n",
      "Test Error: Loss = 0.061412 \n",
      "\n",
      "Epoch 195\n",
      "-------------------------------\n",
      "loss: 0.017360  [    0/  800]\n",
      "loss: 0.016164  [  200/  800]\n",
      "loss: 0.020506  [  400/  800]\n",
      "loss: 0.015706  [  600/  800]\n",
      "Test Error: Loss = 0.057892 \n",
      "\n",
      "Epoch 196\n",
      "-------------------------------\n",
      "loss: 0.013556  [    0/  800]\n",
      "loss: 0.018002  [  200/  800]\n",
      "loss: 0.015672  [  400/  800]\n",
      "loss: 0.019155  [  600/  800]\n",
      "Test Error: Loss = 0.062338 \n",
      "\n",
      "Epoch 197\n",
      "-------------------------------\n",
      "loss: 0.016057  [    0/  800]\n",
      "loss: 0.016773  [  200/  800]\n",
      "loss: 0.015592  [  400/  800]\n",
      "loss: 0.013481  [  600/  800]\n",
      "Test Error: Loss = 0.057785 \n",
      "\n",
      "Epoch 198\n",
      "-------------------------------\n",
      "loss: 0.015989  [    0/  800]\n",
      "loss: 0.015846  [  200/  800]\n",
      "loss: 0.014735  [  400/  800]\n",
      "loss: 0.012909  [  600/  800]\n",
      "Test Error: Loss = 0.060877 \n",
      "\n",
      "Epoch 199\n",
      "-------------------------------\n",
      "loss: 0.013921  [    0/  800]\n",
      "loss: 0.013536  [  200/  800]\n",
      "loss: 0.016001  [  400/  800]\n",
      "loss: 0.016299  [  600/  800]\n",
      "Test Error: Loss = 0.063299 \n",
      "\n",
      "Epoch 200\n",
      "-------------------------------\n",
      "loss: 0.016408  [    0/  800]\n",
      "loss: 0.012927  [  200/  800]\n",
      "loss: 0.016600  [  400/  800]\n",
      "loss: 0.015705  [  600/  800]\n",
      "Test Error: Loss = 0.062072 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "### Train the model\n",
    "epochs = 200\n",
    "loss_list=[]\n",
    "test_loss_list=[]\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    loss_list = train(train_loader, model, loss_fn, optimizer,loss_list)\n",
    "    test_loss_list = test(test_loader, model, test_loss_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.plot(loss_list)\n",
    "axes = plt.gca()\n",
    "plt.title('Training Loss')\n",
    "plt.xlabel('time')\n",
    "plt.ylabel('loss')\n",
    "axes.set_ylim([0,0.4])\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(test_loss_list)\n",
    "axes = plt.gca()\n",
    "plt.title('Test Loss')\n",
    "plt.xlabel('data')\n",
    "plt.ylabel('loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.6677, 0.4278, 0.2584, 0.7262, 0.5235, 0.6059],\n",
      "       grad_fn=<SelectBackward>)\n",
      "tensor([0.6953, 0.6301, 0.3016, 0.8754, 0.6919, 0.3048])\n"
     ]
    }
   ],
   "source": [
    "n = np.random.randint(0,200)\n",
    "pred = model(x_test_tensor[n])\n",
    "print(pred[0])\n",
    "print(y_test_tensor[n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
