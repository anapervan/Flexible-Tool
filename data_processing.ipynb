{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# df = pd.read_csv('/home/ana/Documents/Code/Flexible-Tool/data_3.csv', sep = \" \", names = ['name', 'value'])\n",
    "\n",
    "df = pd.read_csv('/home/bowen/Documents/Rod_manipulation/Flexible-Tool/data_3.csv', sep = \" \", names = ['name', 'value'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a</td>\n",
       "      <td>[0.33293958 0.8473282  0.15392336 0.29004178 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>q</td>\n",
       "      <td>[[1.0, 0.99992538099, 0.99977404976, 0.9995438...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>det_J</td>\n",
       "      <td>[0.0, 7.07220859050288e-126, -2.72470521632022...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a</td>\n",
       "      <td>[0.71559696 0.81872338 0.58718161 0.49673672 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>q</td>\n",
       "      <td>[[1.0, 0.99993177485, 0.99979535014, 0.9995907...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61480</th>\n",
       "      <td>q</td>\n",
       "      <td>[[1.0, 0.99990860689, 0.99972379506, 0.9994435...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61481</th>\n",
       "      <td>det_J</td>\n",
       "      <td>[0.0, -4.682170536930135e-136, 2.2714666973773...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61482</th>\n",
       "      <td>a</td>\n",
       "      <td>[1.93747550e-01 7.99483797e-04 9.74408549e-02 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61483</th>\n",
       "      <td>q</td>\n",
       "      <td>[[1.0, 1.0000000179, 1.000000068, 1.0000001612...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61484</th>\n",
       "      <td>det_J</td>\n",
       "      <td>[0.0, -8.157192375291071e-132, -1.004244139525...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>61485 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        name                                              value\n",
       "0          a  [0.33293958 0.8473282  0.15392336 0.29004178 0...\n",
       "1          q  [[1.0, 0.99992538099, 0.99977404976, 0.9995438...\n",
       "2      det_J  [0.0, 7.07220859050288e-126, -2.72470521632022...\n",
       "3          a  [0.71559696 0.81872338 0.58718161 0.49673672 0...\n",
       "4          q  [[1.0, 0.99993177485, 0.99979535014, 0.9995907...\n",
       "...      ...                                                ...\n",
       "61480      q  [[1.0, 0.99990860689, 0.99972379506, 0.9994435...\n",
       "61481  det_J  [0.0, -4.682170536930135e-136, 2.2714666973773...\n",
       "61482      a  [1.93747550e-01 7.99483797e-04 9.74408549e-02 ...\n",
       "61483      q  [[1.0, 1.0000000179, 1.000000068, 1.0000001612...\n",
       "61484  det_J  [0.0, -8.157192375291071e-132, -1.004244139525...\n",
       "\n",
       "[61485 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df.dropna(inplace = True)\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_rows = df.shape[0]\n",
    "data_trials = int(num_rows/3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.DataFrame()\n",
    "for r in range(len(df)):\n",
    "    if r % 3 == 0:\n",
    "        df0 = df.iloc[r,1:]\n",
    "        df0.value\n",
    "        df0 = df0.str.strip('[[[ ')\n",
    "        df0 = df0.str.strip('[]')\n",
    "        df0 = df0.value.split()\n",
    "        df0 = np.array(df0,dtype=float)\n",
    "        df2 = df2.append(pd.DataFrame(df0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(122970, 1)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.head(12)\n",
    "df2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(122970, 1)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = pd.DataFrame()\n",
    "for i in range(len(df)):\n",
    "    if i % 3 == 1:\n",
    "        df1 = df.iloc[i,1:]\n",
    "        df1 = df1.value\n",
    "        df1 = df1.replace('[','')\n",
    "        df1 = df1.replace(']','')\n",
    "        df1 = df1.split(',')\n",
    "        df1 = np.array(df1,dtype=float)\n",
    "        df3 = df3.append(pd.DataFrame(df1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32792000, 1)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_array = df3.to_numpy()\n",
    "tmp = []\n",
    "for r in q_array:\n",
    "    tmp.append(np.transpose(np.asarray([r])).astype(np.float32))\n",
    "q_array = np.asarray(tmp.copy())\n",
    "type(q_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20495, 16, 100)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_array = q_array.reshape(data_trials,16,100)\n",
    "q_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_array = df2.to_numpy()\n",
    "tmp2 = []\n",
    "for i in a_array:\n",
    "    tmp2.append(np.transpose(np.asarray([i])).astype(np.float32))\n",
    "a_array = np.asarray(tmp2.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20495, 6)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_array = a_array.reshape(data_trials,6)\n",
    "a_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = (q_array[0:int(0.8*data_trials),:,:]).astype(np.float32) # training data from csv/pandas (80% of existing data?)\n",
    "test_x = (q_array[int(0.8*data_trials):data_trials,:,:]).astype(np.float32) # test data from csv/pandas (remaining ~20% of data)\n",
    "test_x = np.expand_dims(test_x, 1) # add dimension for neural net\n",
    "\n",
    "train_y = (a_array[0:int(0.8*data_trials),:]).astype(np.float32)\n",
    "test_y = (a_array[int(0.8*data_trials):data_trials,:]).astype(np.float32)\n",
    "\n",
    "x_test_tensor = torch.from_numpy(test_x)\n",
    "y_test_tensor = torch.from_numpy(test_y)\n",
    "test_data = [(x_test_tensor[i],y_test_tensor[i]) for i in range(x_test_tensor.shape[0])]\n",
    "\n",
    "# print(train_x.shape)\n",
    "# print(x_test_tensor.shape)\n",
    "# print(y_test_tensor.shape)\n",
    "# print(len(test_data))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 0\n",
      "Shape of x:  torch.Size([1000, 16, 100]) torch.float32\n",
      "Shape of y:  torch.Size([1000, 6]) torch.float32\n"
     ]
    }
   ],
   "source": [
    "x_train_tensor = torch.from_numpy(train_x)\n",
    "y_train_tensor = torch.from_numpy(train_y)\n",
    "\n",
    "# xtrain_tensor = torch.utils.data.TensorDataset(train_x)\n",
    "# ytrain_tensor = torch.utils.data.TensorDataset(train_y)\n",
    "\n",
    "train_dataset = torch.utils.data.TensorDataset(x_train_tensor, y_train_tensor)\n",
    "test_dataset = torch.utils.data.TensorDataset(x_test_tensor, y_test_tensor)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size = 1000, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size = 1000, shuffle=True)\n",
    "\n",
    "\n",
    "for batch, (x, y) in enumerate(train_loader):\n",
    "    print(\"batch\", batch)\n",
    "    print(\"Shape of x: \", x.shape, x.dtype)\n",
    "    print(\"Shape of y: \", y.shape, y.dtype)\n",
    "    break\n",
    "\n",
    "\n",
    "# trainset_x = torch.utils.data.DataLoader(train_x, batch_size=10, shuffle=True)\n",
    "# testset_x = torch.utils.data.DataLoader(test_x, batch_size=10, shuffle=True)\n",
    "# trainset_y = torch.utils.data.DataLoader(train_y, batch_size=10, shuffle=True)\n",
    "# testset_y = torch.utils.data.DataLoader(test_y, batch_size=10, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (ls): LSTM(16, 32, num_layers=2, batch_first=True)\n",
      "  (linear): Linear(in_features=32, out_features=6, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "            \n",
    "        self.ls = nn.LSTM(16,32,2, batch_first = True)\n",
    "        self.linear = nn.Linear(32,6)\n",
    "            \n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size = x.shape[0] \n",
    "        x = self.flatten(x)\n",
    "        x = torch.reshape(x, (batch_size, 100, 16)) \n",
    "        output,(h,c) = self.ls(x)\n",
    "        output = self.linear(h[-1,...]) \n",
    "        return nn.Sigmoid()(output)\n",
    "\n",
    "model = Net()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "### loss function and optimizer for training \n",
    "loss_fn = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-2)\n",
    "\n",
    "### Functions for training and testing the model\n",
    "def train(dataloader, model, loss_fn, optimizer,loss_list):\n",
    "    size = len(dataloader.dataset)\n",
    "    for batch, (x,y) in enumerate(dataloader):\n",
    "\n",
    "#         print(\"batch \", batch)\n",
    "#         print(\"Shape of x: \", x.shape)\n",
    "#         print(\"Shape of y: \", y.shape)\n",
    "    \n",
    "        # Compute prediction error\n",
    "        pred = model(x)\n",
    "#         print(\"pred\", pred)\n",
    "#         print(\"y\", y)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch % 10 == 0:\n",
    "            loss, current = loss.item(), batch * len(x)\n",
    "            loss_list.append(loss)\n",
    "        if batch % 20 == 0:\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "    return loss_list\n",
    "\n",
    "def test(dataloader, model,test_loss_list):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            pred = model(X)\n",
    "#             print(\"pred\",pred.shape)\n",
    "#             print(\"y\",y.shape)\n",
    "            test_loss += loss_fn(pred, y)\n",
    "    print(f\"Test Error: Loss = {test_loss:>8f} \\n\")\n",
    "    test_loss_list.append(test_loss)\n",
    "    return test_loss_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 0.083183  [    0/16396]\n",
      "Test Error: Loss = 0.419925 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.084061  [    0/16396]\n",
      "Test Error: Loss = 0.352430 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.068787  [    0/16396]\n",
      "Test Error: Loss = 0.297297 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.058529  [    0/16396]\n",
      "Test Error: Loss = 0.284979 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.057835  [    0/16396]\n",
      "Test Error: Loss = 0.280872 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.054555  [    0/16396]\n",
      "Test Error: Loss = 0.275844 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.054252  [    0/16396]\n",
      "Test Error: Loss = 0.276401 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.053811  [    0/16396]\n",
      "Test Error: Loss = 0.271017 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.053958  [    0/16396]\n",
      "Test Error: Loss = 0.259272 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.051750  [    0/16396]\n",
      "Test Error: Loss = 0.252887 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 0.050732  [    0/16396]\n",
      "Test Error: Loss = 0.236935 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 0.047089  [    0/16396]\n",
      "Test Error: Loss = 0.222557 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 0.043095  [    0/16396]\n",
      "Test Error: Loss = 0.220355 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 0.043802  [    0/16396]\n",
      "Test Error: Loss = 0.212095 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 0.042445  [    0/16396]\n",
      "Test Error: Loss = 0.213414 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 0.042891  [    0/16396]\n",
      "Test Error: Loss = 0.216160 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 0.042881  [    0/16396]\n",
      "Test Error: Loss = 0.208868 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 0.041509  [    0/16396]\n",
      "Test Error: Loss = 0.203205 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 0.039060  [    0/16396]\n",
      "Test Error: Loss = 0.234290 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 0.045267  [    0/16396]\n",
      "Test Error: Loss = 0.213265 \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "loss: 0.040204  [    0/16396]\n",
      "Test Error: Loss = 0.203791 \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "loss: 0.041227  [    0/16396]\n",
      "Test Error: Loss = 0.205272 \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "loss: 0.040569  [    0/16396]\n",
      "Test Error: Loss = 0.205382 \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "loss: 0.039331  [    0/16396]\n",
      "Test Error: Loss = 0.198137 \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "loss: 0.037925  [    0/16396]\n",
      "Test Error: Loss = 0.216173 \n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "loss: 0.042515  [    0/16396]\n",
      "Test Error: Loss = 0.187808 \n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "loss: 0.036806  [    0/16396]\n",
      "Test Error: Loss = 0.189355 \n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "loss: 0.037368  [    0/16396]\n",
      "Test Error: Loss = 0.164073 \n",
      "\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "loss: 0.032357  [    0/16396]\n",
      "Test Error: Loss = 0.168726 \n",
      "\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "loss: 0.032903  [    0/16396]\n",
      "Test Error: Loss = 0.149334 \n",
      "\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "loss: 0.030063  [    0/16396]\n",
      "Test Error: Loss = 0.144587 \n",
      "\n",
      "Epoch 32\n",
      "-------------------------------\n",
      "loss: 0.027530  [    0/16396]\n",
      "Test Error: Loss = 0.133995 \n",
      "\n",
      "Epoch 33\n",
      "-------------------------------\n",
      "loss: 0.026477  [    0/16396]\n",
      "Test Error: Loss = 0.150684 \n",
      "\n",
      "Epoch 34\n",
      "-------------------------------\n",
      "loss: 0.029129  [    0/16396]\n",
      "Test Error: Loss = 0.134018 \n",
      "\n",
      "Epoch 35\n",
      "-------------------------------\n",
      "loss: 0.026330  [    0/16396]\n",
      "Test Error: Loss = 0.134449 \n",
      "\n",
      "Epoch 36\n",
      "-------------------------------\n",
      "loss: 0.028293  [    0/16396]\n",
      "Test Error: Loss = 0.132024 \n",
      "\n",
      "Epoch 37\n",
      "-------------------------------\n",
      "loss: 0.026299  [    0/16396]\n",
      "Test Error: Loss = 0.131801 \n",
      "\n",
      "Epoch 38\n",
      "-------------------------------\n",
      "loss: 0.026736  [    0/16396]\n",
      "Test Error: Loss = 0.138825 \n",
      "\n",
      "Epoch 39\n",
      "-------------------------------\n",
      "loss: 0.026864  [    0/16396]\n",
      "Test Error: Loss = 0.139947 \n",
      "\n",
      "Epoch 40\n",
      "-------------------------------\n",
      "loss: 0.027745  [    0/16396]\n",
      "Test Error: Loss = 0.134394 \n",
      "\n",
      "Epoch 41\n",
      "-------------------------------\n",
      "loss: 0.025838  [    0/16396]\n",
      "Test Error: Loss = 0.186329 \n",
      "\n",
      "Epoch 42\n",
      "-------------------------------\n",
      "loss: 0.038352  [    0/16396]\n",
      "Test Error: Loss = 0.131821 \n",
      "\n",
      "Epoch 43\n",
      "-------------------------------\n",
      "loss: 0.025124  [    0/16396]\n",
      "Test Error: Loss = 0.118383 \n",
      "\n",
      "Epoch 44\n",
      "-------------------------------\n",
      "loss: 0.022977  [    0/16396]\n",
      "Test Error: Loss = 0.098086 \n",
      "\n",
      "Epoch 45\n",
      "-------------------------------\n",
      "loss: 0.019353  [    0/16396]\n",
      "Test Error: Loss = 0.132842 \n",
      "\n",
      "Epoch 46\n",
      "-------------------------------\n",
      "loss: 0.025107  [    0/16396]\n",
      "Test Error: Loss = 0.091074 \n",
      "\n",
      "Epoch 47\n",
      "-------------------------------\n",
      "loss: 0.018339  [    0/16396]\n",
      "Test Error: Loss = 0.082861 \n",
      "\n",
      "Epoch 48\n",
      "-------------------------------\n",
      "loss: 0.016327  [    0/16396]\n",
      "Test Error: Loss = 0.114660 \n",
      "\n",
      "Epoch 49\n",
      "-------------------------------\n",
      "loss: 0.022834  [    0/16396]\n",
      "Test Error: Loss = 0.095886 \n",
      "\n",
      "Epoch 50\n",
      "-------------------------------\n",
      "loss: 0.017925  [    0/16396]\n",
      "Test Error: Loss = 0.080349 \n",
      "\n",
      "Epoch 51\n",
      "-------------------------------\n",
      "loss: 0.016320  [    0/16396]\n",
      "Test Error: Loss = 0.077170 \n",
      "\n",
      "Epoch 52\n",
      "-------------------------------\n",
      "loss: 0.015557  [    0/16396]\n",
      "Test Error: Loss = 0.079136 \n",
      "\n",
      "Epoch 53\n",
      "-------------------------------\n",
      "loss: 0.014865  [    0/16396]\n",
      "Test Error: Loss = 0.087056 \n",
      "\n",
      "Epoch 54\n",
      "-------------------------------\n",
      "loss: 0.017583  [    0/16396]\n",
      "Test Error: Loss = 0.077783 \n",
      "\n",
      "Epoch 55\n",
      "-------------------------------\n",
      "loss: 0.014950  [    0/16396]\n",
      "Test Error: Loss = 0.095301 \n",
      "\n",
      "Epoch 56\n",
      "-------------------------------\n",
      "loss: 0.019735  [    0/16396]\n",
      "Test Error: Loss = 0.081990 \n",
      "\n",
      "Epoch 57\n",
      "-------------------------------\n",
      "loss: 0.016033  [    0/16396]\n",
      "Test Error: Loss = 0.079879 \n",
      "\n",
      "Epoch 58\n",
      "-------------------------------\n",
      "loss: 0.015858  [    0/16396]\n",
      "Test Error: Loss = 0.079148 \n",
      "\n",
      "Epoch 59\n",
      "-------------------------------\n",
      "loss: 0.015107  [    0/16396]\n",
      "Test Error: Loss = 0.076166 \n",
      "\n",
      "Epoch 60\n",
      "-------------------------------\n",
      "loss: 0.015805  [    0/16396]\n",
      "Test Error: Loss = 0.079794 \n",
      "\n",
      "Epoch 61\n",
      "-------------------------------\n",
      "loss: 0.015826  [    0/16396]\n",
      "Test Error: Loss = 0.079959 \n",
      "\n",
      "Epoch 62\n",
      "-------------------------------\n",
      "loss: 0.015731  [    0/16396]\n",
      "Test Error: Loss = 0.076632 \n",
      "\n",
      "Epoch 63\n",
      "-------------------------------\n",
      "loss: 0.014150  [    0/16396]\n",
      "Test Error: Loss = 0.073728 \n",
      "\n",
      "Epoch 64\n",
      "-------------------------------\n",
      "loss: 0.013975  [    0/16396]\n",
      "Test Error: Loss = 0.077386 \n",
      "\n",
      "Epoch 65\n",
      "-------------------------------\n",
      "loss: 0.014537  [    0/16396]\n",
      "Test Error: Loss = 0.086430 \n",
      "\n",
      "Epoch 66\n",
      "-------------------------------\n",
      "loss: 0.016247  [    0/16396]\n",
      "Test Error: Loss = 0.073874 \n",
      "\n",
      "Epoch 67\n",
      "-------------------------------\n",
      "loss: 0.013627  [    0/16396]\n",
      "Test Error: Loss = 0.080158 \n",
      "\n",
      "Epoch 68\n",
      "-------------------------------\n",
      "loss: 0.015053  [    0/16396]\n",
      "Test Error: Loss = 0.079969 \n",
      "\n",
      "Epoch 69\n",
      "-------------------------------\n",
      "loss: 0.014869  [    0/16396]\n",
      "Test Error: Loss = 0.073740 \n",
      "\n",
      "Epoch 70\n",
      "-------------------------------\n",
      "loss: 0.014364  [    0/16396]\n",
      "Test Error: Loss = 0.076896 \n",
      "\n",
      "Epoch 71\n",
      "-------------------------------\n",
      "loss: 0.015018  [    0/16396]\n",
      "Test Error: Loss = 0.074791 \n",
      "\n",
      "Epoch 72\n",
      "-------------------------------\n",
      "loss: 0.014571  [    0/16396]\n",
      "Test Error: Loss = 0.074896 \n",
      "\n",
      "Epoch 73\n",
      "-------------------------------\n",
      "loss: 0.013704  [    0/16396]\n",
      "Test Error: Loss = 0.071822 \n",
      "\n",
      "Epoch 74\n",
      "-------------------------------\n",
      "loss: 0.014113  [    0/16396]\n",
      "Test Error: Loss = 0.082523 \n",
      "\n",
      "Epoch 75\n",
      "-------------------------------\n",
      "loss: 0.016709  [    0/16396]\n",
      "Test Error: Loss = 0.078982 \n",
      "\n",
      "Epoch 76\n",
      "-------------------------------\n",
      "loss: 0.014623  [    0/16396]\n",
      "Test Error: Loss = 0.071427 \n",
      "\n",
      "Epoch 77\n",
      "-------------------------------\n",
      "loss: 0.014854  [    0/16396]\n",
      "Test Error: Loss = 0.071319 \n",
      "\n",
      "Epoch 78\n",
      "-------------------------------\n",
      "loss: 0.013373  [    0/16396]\n",
      "Test Error: Loss = 0.072846 \n",
      "\n",
      "Epoch 79\n",
      "-------------------------------\n",
      "loss: 0.014401  [    0/16396]\n",
      "Test Error: Loss = 0.074142 \n",
      "\n",
      "Epoch 80\n",
      "-------------------------------\n",
      "loss: 0.014220  [    0/16396]\n",
      "Test Error: Loss = 0.076051 \n",
      "\n",
      "Epoch 81\n",
      "-------------------------------\n",
      "loss: 0.014548  [    0/16396]\n",
      "Test Error: Loss = 0.074283 \n",
      "\n",
      "Epoch 82\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.014478  [    0/16396]\n",
      "Test Error: Loss = 0.074128 \n",
      "\n",
      "Epoch 83\n",
      "-------------------------------\n",
      "loss: 0.014655  [    0/16396]\n",
      "Test Error: Loss = 0.069633 \n",
      "\n",
      "Epoch 84\n",
      "-------------------------------\n",
      "loss: 0.013886  [    0/16396]\n",
      "Test Error: Loss = 0.079000 \n",
      "\n",
      "Epoch 85\n",
      "-------------------------------\n",
      "loss: 0.015256  [    0/16396]\n",
      "Test Error: Loss = 0.071674 \n",
      "\n",
      "Epoch 86\n",
      "-------------------------------\n",
      "loss: 0.013411  [    0/16396]\n",
      "Test Error: Loss = 0.071847 \n",
      "\n",
      "Epoch 87\n",
      "-------------------------------\n",
      "loss: 0.013478  [    0/16396]\n",
      "Test Error: Loss = 0.075710 \n",
      "\n",
      "Epoch 88\n",
      "-------------------------------\n",
      "loss: 0.013883  [    0/16396]\n",
      "Test Error: Loss = 0.069563 \n",
      "\n",
      "Epoch 89\n",
      "-------------------------------\n",
      "loss: 0.013118  [    0/16396]\n",
      "Test Error: Loss = 0.071210 \n",
      "\n",
      "Epoch 90\n",
      "-------------------------------\n",
      "loss: 0.013249  [    0/16396]\n",
      "Test Error: Loss = 0.072667 \n",
      "\n",
      "Epoch 91\n",
      "-------------------------------\n",
      "loss: 0.014936  [    0/16396]\n",
      "Test Error: Loss = 0.074825 \n",
      "\n",
      "Epoch 92\n",
      "-------------------------------\n",
      "loss: 0.014361  [    0/16396]\n",
      "Test Error: Loss = 0.071621 \n",
      "\n",
      "Epoch 93\n",
      "-------------------------------\n",
      "loss: 0.013779  [    0/16396]\n",
      "Test Error: Loss = 0.072629 \n",
      "\n",
      "Epoch 94\n",
      "-------------------------------\n",
      "loss: 0.014013  [    0/16396]\n",
      "Test Error: Loss = 0.071717 \n",
      "\n",
      "Epoch 95\n",
      "-------------------------------\n",
      "loss: 0.014461  [    0/16396]\n",
      "Test Error: Loss = 0.076656 \n",
      "\n",
      "Epoch 96\n",
      "-------------------------------\n",
      "loss: 0.014322  [    0/16396]\n",
      "Test Error: Loss = 0.070549 \n",
      "\n",
      "Epoch 97\n",
      "-------------------------------\n",
      "loss: 0.014180  [    0/16396]\n",
      "Test Error: Loss = 0.071649 \n",
      "\n",
      "Epoch 98\n",
      "-------------------------------\n",
      "loss: 0.014364  [    0/16396]\n",
      "Test Error: Loss = 0.074828 \n",
      "\n",
      "Epoch 99\n",
      "-------------------------------\n",
      "loss: 0.014533  [    0/16396]\n",
      "Test Error: Loss = 0.073215 \n",
      "\n",
      "Epoch 100\n",
      "-------------------------------\n",
      "loss: 0.014727  [    0/16396]\n",
      "Test Error: Loss = 0.071593 \n",
      "\n",
      "Epoch 101\n",
      "-------------------------------\n",
      "loss: 0.013285  [    0/16396]\n",
      "Test Error: Loss = 0.069648 \n",
      "\n",
      "Epoch 102\n",
      "-------------------------------\n",
      "loss: 0.013055  [    0/16396]\n",
      "Test Error: Loss = 0.072662 \n",
      "\n",
      "Epoch 103\n",
      "-------------------------------\n",
      "loss: 0.015313  [    0/16396]\n",
      "Test Error: Loss = 0.070921 \n",
      "\n",
      "Epoch 104\n",
      "-------------------------------\n",
      "loss: 0.013547  [    0/16396]\n",
      "Test Error: Loss = 0.069996 \n",
      "\n",
      "Epoch 105\n",
      "-------------------------------\n",
      "loss: 0.013694  [    0/16396]\n",
      "Test Error: Loss = 0.068746 \n",
      "\n",
      "Epoch 106\n",
      "-------------------------------\n",
      "loss: 0.013443  [    0/16396]\n",
      "Test Error: Loss = 0.076856 \n",
      "\n",
      "Epoch 107\n",
      "-------------------------------\n",
      "loss: 0.014708  [    0/16396]\n",
      "Test Error: Loss = 0.072426 \n",
      "\n",
      "Epoch 108\n",
      "-------------------------------\n",
      "loss: 0.013586  [    0/16396]\n",
      "Test Error: Loss = 0.070824 \n",
      "\n",
      "Epoch 109\n",
      "-------------------------------\n",
      "loss: 0.014776  [    0/16396]\n",
      "Test Error: Loss = 0.071944 \n",
      "\n",
      "Epoch 110\n",
      "-------------------------------\n",
      "loss: 0.013053  [    0/16396]\n",
      "Test Error: Loss = 0.067112 \n",
      "\n",
      "Epoch 111\n",
      "-------------------------------\n",
      "loss: 0.013694  [    0/16396]\n",
      "Test Error: Loss = 0.072725 \n",
      "\n",
      "Epoch 112\n",
      "-------------------------------\n",
      "loss: 0.013828  [    0/16396]\n",
      "Test Error: Loss = 0.071512 \n",
      "\n",
      "Epoch 113\n",
      "-------------------------------\n",
      "loss: 0.013736  [    0/16396]\n",
      "Test Error: Loss = 0.068309 \n",
      "\n",
      "Epoch 114\n",
      "-------------------------------\n",
      "loss: 0.013788  [    0/16396]\n",
      "Test Error: Loss = 0.069822 \n",
      "\n",
      "Epoch 115\n",
      "-------------------------------\n",
      "loss: 0.013701  [    0/16396]\n",
      "Test Error: Loss = 0.071905 \n",
      "\n",
      "Epoch 116\n",
      "-------------------------------\n",
      "loss: 0.013463  [    0/16396]\n",
      "Test Error: Loss = 0.077531 \n",
      "\n",
      "Epoch 117\n",
      "-------------------------------\n",
      "loss: 0.014401  [    0/16396]\n",
      "Test Error: Loss = 0.068175 \n",
      "\n",
      "Epoch 118\n",
      "-------------------------------\n",
      "loss: 0.013680  [    0/16396]\n",
      "Test Error: Loss = 0.068077 \n",
      "\n",
      "Epoch 119\n",
      "-------------------------------\n",
      "loss: 0.013136  [    0/16396]\n",
      "Test Error: Loss = 0.073237 \n",
      "\n",
      "Epoch 120\n",
      "-------------------------------\n",
      "loss: 0.013610  [    0/16396]\n",
      "Test Error: Loss = 0.073606 \n",
      "\n",
      "Epoch 121\n",
      "-------------------------------\n",
      "loss: 0.013362  [    0/16396]\n",
      "Test Error: Loss = 0.068232 \n",
      "\n",
      "Epoch 122\n",
      "-------------------------------\n",
      "loss: 0.013077  [    0/16396]\n",
      "Test Error: Loss = 0.070489 \n",
      "\n",
      "Epoch 123\n",
      "-------------------------------\n",
      "loss: 0.013349  [    0/16396]\n",
      "Test Error: Loss = 0.070178 \n",
      "\n",
      "Epoch 124\n",
      "-------------------------------\n",
      "loss: 0.013154  [    0/16396]\n",
      "Test Error: Loss = 0.069144 \n",
      "\n",
      "Epoch 125\n",
      "-------------------------------\n",
      "loss: 0.013432  [    0/16396]\n",
      "Test Error: Loss = 0.067709 \n",
      "\n",
      "Epoch 126\n",
      "-------------------------------\n",
      "loss: 0.013809  [    0/16396]\n",
      "Test Error: Loss = 0.068263 \n",
      "\n",
      "Epoch 127\n",
      "-------------------------------\n",
      "loss: 0.013184  [    0/16396]\n",
      "Test Error: Loss = 0.072006 \n",
      "\n",
      "Epoch 128\n",
      "-------------------------------\n",
      "loss: 0.013262  [    0/16396]\n",
      "Test Error: Loss = 0.075888 \n",
      "\n",
      "Epoch 129\n",
      "-------------------------------\n",
      "loss: 0.013830  [    0/16396]\n",
      "Test Error: Loss = 0.072800 \n",
      "\n",
      "Epoch 130\n",
      "-------------------------------\n",
      "loss: 0.013810  [    0/16396]\n",
      "Test Error: Loss = 0.072508 \n",
      "\n",
      "Epoch 131\n",
      "-------------------------------\n",
      "loss: 0.014311  [    0/16396]\n",
      "Test Error: Loss = 0.070396 \n",
      "\n",
      "Epoch 132\n",
      "-------------------------------\n",
      "loss: 0.013575  [    0/16396]\n",
      "Test Error: Loss = 0.072847 \n",
      "\n",
      "Epoch 133\n",
      "-------------------------------\n",
      "loss: 0.013627  [    0/16396]\n",
      "Test Error: Loss = 0.069674 \n",
      "\n",
      "Epoch 134\n",
      "-------------------------------\n",
      "loss: 0.013140  [    0/16396]\n",
      "Test Error: Loss = 0.066894 \n",
      "\n",
      "Epoch 135\n",
      "-------------------------------\n",
      "loss: 0.013237  [    0/16396]\n",
      "Test Error: Loss = 0.071220 \n",
      "\n",
      "Epoch 136\n",
      "-------------------------------\n",
      "loss: 0.013238  [    0/16396]\n",
      "Test Error: Loss = 0.072511 \n",
      "\n",
      "Epoch 137\n",
      "-------------------------------\n",
      "loss: 0.014605  [    0/16396]\n",
      "Test Error: Loss = 0.077421 \n",
      "\n",
      "Epoch 138\n",
      "-------------------------------\n",
      "loss: 0.014293  [    0/16396]\n",
      "Test Error: Loss = 0.072904 \n",
      "\n",
      "Epoch 139\n",
      "-------------------------------\n",
      "loss: 0.013736  [    0/16396]\n",
      "Test Error: Loss = 0.068278 \n",
      "\n",
      "Epoch 140\n",
      "-------------------------------\n",
      "loss: 0.013032  [    0/16396]\n",
      "Test Error: Loss = 0.071302 \n",
      "\n",
      "Epoch 141\n",
      "-------------------------------\n",
      "loss: 0.014427  [    0/16396]\n",
      "Test Error: Loss = 0.067907 \n",
      "\n",
      "Epoch 142\n",
      "-------------------------------\n",
      "loss: 0.013825  [    0/16396]\n",
      "Test Error: Loss = 0.070919 \n",
      "\n",
      "Epoch 143\n",
      "-------------------------------\n",
      "loss: 0.013593  [    0/16396]\n",
      "Test Error: Loss = 0.070668 \n",
      "\n",
      "Epoch 144\n",
      "-------------------------------\n",
      "loss: 0.013598  [    0/16396]\n",
      "Test Error: Loss = 0.067119 \n",
      "\n",
      "Epoch 145\n",
      "-------------------------------\n",
      "loss: 0.013585  [    0/16396]\n",
      "Test Error: Loss = 0.072084 \n",
      "\n",
      "Epoch 146\n",
      "-------------------------------\n",
      "loss: 0.013925  [    0/16396]\n",
      "Test Error: Loss = 0.070585 \n",
      "\n",
      "Epoch 147\n",
      "-------------------------------\n",
      "loss: 0.013116  [    0/16396]\n",
      "Test Error: Loss = 0.070555 \n",
      "\n",
      "Epoch 148\n",
      "-------------------------------\n",
      "loss: 0.013885  [    0/16396]\n",
      "Test Error: Loss = 0.072599 \n",
      "\n",
      "Epoch 149\n",
      "-------------------------------\n",
      "loss: 0.013766  [    0/16396]\n",
      "Test Error: Loss = 0.072014 \n",
      "\n",
      "Epoch 150\n",
      "-------------------------------\n",
      "loss: 0.014472  [    0/16396]\n",
      "Test Error: Loss = 0.070346 \n",
      "\n",
      "Epoch 151\n",
      "-------------------------------\n",
      "loss: 0.013310  [    0/16396]\n",
      "Test Error: Loss = 0.069262 \n",
      "\n",
      "Epoch 152\n",
      "-------------------------------\n",
      "loss: 0.012657  [    0/16396]\n",
      "Test Error: Loss = 0.078203 \n",
      "\n",
      "Epoch 153\n",
      "-------------------------------\n",
      "loss: 0.015141  [    0/16396]\n",
      "Test Error: Loss = 0.075402 \n",
      "\n",
      "Epoch 154\n",
      "-------------------------------\n",
      "loss: 0.015390  [    0/16396]\n",
      "Test Error: Loss = 0.072844 \n",
      "\n",
      "Epoch 155\n",
      "-------------------------------\n",
      "loss: 0.014181  [    0/16396]\n",
      "Test Error: Loss = 0.070210 \n",
      "\n",
      "Epoch 156\n",
      "-------------------------------\n",
      "loss: 0.012601  [    0/16396]\n",
      "Test Error: Loss = 0.072593 \n",
      "\n",
      "Epoch 157\n",
      "-------------------------------\n",
      "loss: 0.014053  [    0/16396]\n",
      "Test Error: Loss = 0.068521 \n",
      "\n",
      "Epoch 158\n",
      "-------------------------------\n",
      "loss: 0.013548  [    0/16396]\n",
      "Test Error: Loss = 0.069208 \n",
      "\n",
      "Epoch 159\n",
      "-------------------------------\n",
      "loss: 0.012862  [    0/16396]\n",
      "Test Error: Loss = 0.070766 \n",
      "\n",
      "Epoch 160\n",
      "-------------------------------\n",
      "loss: 0.014487  [    0/16396]\n",
      "Test Error: Loss = 0.065997 \n",
      "\n",
      "Epoch 161\n",
      "-------------------------------\n",
      "loss: 0.012516  [    0/16396]\n",
      "Test Error: Loss = 0.067312 \n",
      "\n",
      "Epoch 162\n",
      "-------------------------------\n",
      "loss: 0.012418  [    0/16396]\n",
      "Test Error: Loss = 0.069493 \n",
      "\n",
      "Epoch 163\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.013153  [    0/16396]\n",
      "Test Error: Loss = 0.068186 \n",
      "\n",
      "Epoch 164\n",
      "-------------------------------\n",
      "loss: 0.013300  [    0/16396]\n",
      "Test Error: Loss = 0.078472 \n",
      "\n",
      "Epoch 165\n",
      "-------------------------------\n",
      "loss: 0.013699  [    0/16396]\n",
      "Test Error: Loss = 0.066720 \n",
      "\n",
      "Epoch 166\n",
      "-------------------------------\n",
      "loss: 0.012894  [    0/16396]\n",
      "Test Error: Loss = 0.069614 \n",
      "\n",
      "Epoch 167\n",
      "-------------------------------\n",
      "loss: 0.012445  [    0/16396]\n",
      "Test Error: Loss = 0.068050 \n",
      "\n",
      "Epoch 168\n",
      "-------------------------------\n",
      "loss: 0.013364  [    0/16396]\n",
      "Test Error: Loss = 0.066586 \n",
      "\n",
      "Epoch 169\n",
      "-------------------------------\n",
      "loss: 0.014141  [    0/16396]\n",
      "Test Error: Loss = 0.074303 \n",
      "\n",
      "Epoch 170\n",
      "-------------------------------\n",
      "loss: 0.014678  [    0/16396]\n",
      "Test Error: Loss = 0.070368 \n",
      "\n",
      "Epoch 171\n",
      "-------------------------------\n",
      "loss: 0.013335  [    0/16396]\n",
      "Test Error: Loss = 0.065650 \n",
      "\n",
      "Epoch 172\n",
      "-------------------------------\n",
      "loss: 0.013306  [    0/16396]\n",
      "Test Error: Loss = 0.068535 \n",
      "\n",
      "Epoch 173\n",
      "-------------------------------\n",
      "loss: 0.012711  [    0/16396]\n",
      "Test Error: Loss = 0.070622 \n",
      "\n",
      "Epoch 174\n",
      "-------------------------------\n",
      "loss: 0.012780  [    0/16396]\n",
      "Test Error: Loss = 0.071687 \n",
      "\n",
      "Epoch 175\n",
      "-------------------------------\n",
      "loss: 0.013883  [    0/16396]\n",
      "Test Error: Loss = 0.071060 \n",
      "\n",
      "Epoch 176\n",
      "-------------------------------\n",
      "loss: 0.013442  [    0/16396]\n",
      "Test Error: Loss = 0.066206 \n",
      "\n",
      "Epoch 177\n",
      "-------------------------------\n",
      "loss: 0.013158  [    0/16396]\n",
      "Test Error: Loss = 0.069316 \n",
      "\n",
      "Epoch 178\n",
      "-------------------------------\n",
      "loss: 0.013208  [    0/16396]\n",
      "Test Error: Loss = 0.066628 \n",
      "\n",
      "Epoch 179\n",
      "-------------------------------\n",
      "loss: 0.012547  [    0/16396]\n",
      "Test Error: Loss = 0.068560 \n",
      "\n",
      "Epoch 180\n",
      "-------------------------------\n",
      "loss: 0.013021  [    0/16396]\n",
      "Test Error: Loss = 0.069401 \n",
      "\n",
      "Epoch 181\n",
      "-------------------------------\n",
      "loss: 0.013181  [    0/16396]\n",
      "Test Error: Loss = 0.068182 \n",
      "\n",
      "Epoch 182\n",
      "-------------------------------\n",
      "loss: 0.012609  [    0/16396]\n",
      "Test Error: Loss = 0.070417 \n",
      "\n",
      "Epoch 183\n",
      "-------------------------------\n",
      "loss: 0.013239  [    0/16396]\n",
      "Test Error: Loss = 0.072025 \n",
      "\n",
      "Epoch 184\n",
      "-------------------------------\n",
      "loss: 0.013563  [    0/16396]\n",
      "Test Error: Loss = 0.066848 \n",
      "\n",
      "Epoch 185\n",
      "-------------------------------\n",
      "loss: 0.013532  [    0/16396]\n",
      "Test Error: Loss = 0.071425 \n",
      "\n",
      "Epoch 186\n",
      "-------------------------------\n",
      "loss: 0.013805  [    0/16396]\n",
      "Test Error: Loss = 0.070476 \n",
      "\n",
      "Epoch 187\n",
      "-------------------------------\n",
      "loss: 0.013950  [    0/16396]\n",
      "Test Error: Loss = 0.069481 \n",
      "\n",
      "Epoch 188\n",
      "-------------------------------\n",
      "loss: 0.013025  [    0/16396]\n",
      "Test Error: Loss = 0.067806 \n",
      "\n",
      "Epoch 189\n",
      "-------------------------------\n",
      "loss: 0.012974  [    0/16396]\n",
      "Test Error: Loss = 0.067998 \n",
      "\n",
      "Epoch 190\n",
      "-------------------------------\n",
      "loss: 0.013104  [    0/16396]\n",
      "Test Error: Loss = 0.067449 \n",
      "\n",
      "Epoch 191\n",
      "-------------------------------\n",
      "loss: 0.013229  [    0/16396]\n",
      "Test Error: Loss = 0.072236 \n",
      "\n",
      "Epoch 192\n",
      "-------------------------------\n",
      "loss: 0.012596  [    0/16396]\n",
      "Test Error: Loss = 0.068004 \n",
      "\n",
      "Epoch 193\n",
      "-------------------------------\n",
      "loss: 0.012693  [    0/16396]\n",
      "Test Error: Loss = 0.067687 \n",
      "\n",
      "Epoch 194\n",
      "-------------------------------\n",
      "loss: 0.013491  [    0/16396]\n",
      "Test Error: Loss = 0.068279 \n",
      "\n",
      "Epoch 195\n",
      "-------------------------------\n",
      "loss: 0.013468  [    0/16396]\n",
      "Test Error: Loss = 0.071169 \n",
      "\n",
      "Epoch 196\n",
      "-------------------------------\n",
      "loss: 0.013363  [    0/16396]\n",
      "Test Error: Loss = 0.069272 \n",
      "\n",
      "Epoch 197\n",
      "-------------------------------\n",
      "loss: 0.013370  [    0/16396]\n",
      "Test Error: Loss = 0.068663 \n",
      "\n",
      "Epoch 198\n",
      "-------------------------------\n",
      "loss: 0.012932  [    0/16396]\n",
      "Test Error: Loss = 0.069012 \n",
      "\n",
      "Epoch 199\n",
      "-------------------------------\n",
      "loss: 0.012369  [    0/16396]\n",
      "Test Error: Loss = 0.072341 \n",
      "\n",
      "Epoch 200\n",
      "-------------------------------\n",
      "loss: 0.014330  [    0/16396]\n",
      "Test Error: Loss = 0.068567 \n",
      "\n",
      "Epoch 201\n",
      "-------------------------------\n",
      "loss: 0.012323  [    0/16396]\n",
      "Test Error: Loss = 0.071403 \n",
      "\n",
      "Epoch 202\n",
      "-------------------------------\n",
      "loss: 0.013292  [    0/16396]\n",
      "Test Error: Loss = 0.068398 \n",
      "\n",
      "Epoch 203\n",
      "-------------------------------\n",
      "loss: 0.013098  [    0/16396]\n",
      "Test Error: Loss = 0.066601 \n",
      "\n",
      "Epoch 204\n",
      "-------------------------------\n",
      "loss: 0.012312  [    0/16396]\n",
      "Test Error: Loss = 0.069693 \n",
      "\n",
      "Epoch 205\n",
      "-------------------------------\n",
      "loss: 0.013362  [    0/16396]\n",
      "Test Error: Loss = 0.070697 \n",
      "\n",
      "Epoch 206\n",
      "-------------------------------\n",
      "loss: 0.012545  [    0/16396]\n",
      "Test Error: Loss = 0.066693 \n",
      "\n",
      "Epoch 207\n",
      "-------------------------------\n",
      "loss: 0.013098  [    0/16396]\n",
      "Test Error: Loss = 0.069515 \n",
      "\n",
      "Epoch 208\n",
      "-------------------------------\n",
      "loss: 0.012943  [    0/16396]\n",
      "Test Error: Loss = 0.068783 \n",
      "\n",
      "Epoch 209\n",
      "-------------------------------\n",
      "loss: 0.013779  [    0/16396]\n",
      "Test Error: Loss = 0.066566 \n",
      "\n",
      "Epoch 210\n",
      "-------------------------------\n",
      "loss: 0.012618  [    0/16396]\n",
      "Test Error: Loss = 0.070087 \n",
      "\n",
      "Epoch 211\n",
      "-------------------------------\n",
      "loss: 0.012957  [    0/16396]\n",
      "Test Error: Loss = 0.068293 \n",
      "\n",
      "Epoch 212\n",
      "-------------------------------\n",
      "loss: 0.013299  [    0/16396]\n",
      "Test Error: Loss = 0.068563 \n",
      "\n",
      "Epoch 213\n",
      "-------------------------------\n",
      "loss: 0.012534  [    0/16396]\n",
      "Test Error: Loss = 0.069574 \n",
      "\n",
      "Epoch 214\n",
      "-------------------------------\n",
      "loss: 0.013282  [    0/16396]\n",
      "Test Error: Loss = 0.072063 \n",
      "\n",
      "Epoch 215\n",
      "-------------------------------\n",
      "loss: 0.013843  [    0/16396]\n",
      "Test Error: Loss = 0.068842 \n",
      "\n",
      "Epoch 216\n",
      "-------------------------------\n",
      "loss: 0.013505  [    0/16396]\n",
      "Test Error: Loss = 0.068680 \n",
      "\n",
      "Epoch 217\n",
      "-------------------------------\n",
      "loss: 0.013074  [    0/16396]\n",
      "Test Error: Loss = 0.066492 \n",
      "\n",
      "Epoch 218\n",
      "-------------------------------\n",
      "loss: 0.013310  [    0/16396]\n",
      "Test Error: Loss = 0.070831 \n",
      "\n",
      "Epoch 219\n",
      "-------------------------------\n",
      "loss: 0.013079  [    0/16396]\n",
      "Test Error: Loss = 0.070879 \n",
      "\n",
      "Epoch 220\n",
      "-------------------------------\n",
      "loss: 0.013817  [    0/16396]\n",
      "Test Error: Loss = 0.067985 \n",
      "\n",
      "Epoch 221\n",
      "-------------------------------\n",
      "loss: 0.012963  [    0/16396]\n",
      "Test Error: Loss = 0.068988 \n",
      "\n",
      "Epoch 222\n",
      "-------------------------------\n",
      "loss: 0.013583  [    0/16396]\n",
      "Test Error: Loss = 0.069453 \n",
      "\n",
      "Epoch 223\n",
      "-------------------------------\n",
      "loss: 0.013893  [    0/16396]\n",
      "Test Error: Loss = 0.066956 \n",
      "\n",
      "Epoch 224\n",
      "-------------------------------\n",
      "loss: 0.013373  [    0/16396]\n",
      "Test Error: Loss = 0.071118 \n",
      "\n",
      "Epoch 225\n",
      "-------------------------------\n",
      "loss: 0.013311  [    0/16396]\n",
      "Test Error: Loss = 0.068399 \n",
      "\n",
      "Epoch 226\n",
      "-------------------------------\n",
      "loss: 0.013022  [    0/16396]\n",
      "Test Error: Loss = 0.064812 \n",
      "\n",
      "Epoch 227\n",
      "-------------------------------\n",
      "loss: 0.012389  [    0/16396]\n",
      "Test Error: Loss = 0.071464 \n",
      "\n",
      "Epoch 228\n",
      "-------------------------------\n",
      "loss: 0.013127  [    0/16396]\n",
      "Test Error: Loss = 0.065922 \n",
      "\n",
      "Epoch 229\n",
      "-------------------------------\n",
      "loss: 0.012372  [    0/16396]\n",
      "Test Error: Loss = 0.066890 \n",
      "\n",
      "Epoch 230\n",
      "-------------------------------\n",
      "loss: 0.014029  [    0/16396]\n",
      "Test Error: Loss = 0.070058 \n",
      "\n",
      "Epoch 231\n",
      "-------------------------------\n",
      "loss: 0.012901  [    0/16396]\n",
      "Test Error: Loss = 0.066975 \n",
      "\n",
      "Epoch 232\n",
      "-------------------------------\n",
      "loss: 0.012914  [    0/16396]\n",
      "Test Error: Loss = 0.067382 \n",
      "\n",
      "Epoch 233\n",
      "-------------------------------\n",
      "loss: 0.012742  [    0/16396]\n",
      "Test Error: Loss = 0.069552 \n",
      "\n",
      "Epoch 234\n",
      "-------------------------------\n",
      "loss: 0.013171  [    0/16396]\n",
      "Test Error: Loss = 0.070915 \n",
      "\n",
      "Epoch 235\n",
      "-------------------------------\n",
      "loss: 0.014231  [    0/16396]\n",
      "Test Error: Loss = 0.069243 \n",
      "\n",
      "Epoch 236\n",
      "-------------------------------\n",
      "loss: 0.012757  [    0/16396]\n",
      "Test Error: Loss = 0.072285 \n",
      "\n",
      "Epoch 237\n",
      "-------------------------------\n",
      "loss: 0.013054  [    0/16396]\n",
      "Test Error: Loss = 0.069570 \n",
      "\n",
      "Epoch 238\n",
      "-------------------------------\n",
      "loss: 0.012038  [    0/16396]\n",
      "Test Error: Loss = 0.067803 \n",
      "\n",
      "Epoch 239\n",
      "-------------------------------\n",
      "loss: 0.012766  [    0/16396]\n",
      "Test Error: Loss = 0.065580 \n",
      "\n",
      "Epoch 240\n",
      "-------------------------------\n",
      "loss: 0.011764  [    0/16396]\n",
      "Test Error: Loss = 0.066533 \n",
      "\n",
      "Epoch 241\n",
      "-------------------------------\n",
      "loss: 0.013295  [    0/16396]\n",
      "Test Error: Loss = 0.068283 \n",
      "\n",
      "Epoch 242\n",
      "-------------------------------\n",
      "loss: 0.013045  [    0/16396]\n",
      "Test Error: Loss = 0.066272 \n",
      "\n",
      "Epoch 243\n",
      "-------------------------------\n",
      "loss: 0.012308  [    0/16396]\n",
      "Test Error: Loss = 0.067615 \n",
      "\n",
      "Epoch 244\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.013314  [    0/16396]\n",
      "Test Error: Loss = 0.066398 \n",
      "\n",
      "Epoch 245\n",
      "-------------------------------\n",
      "loss: 0.012736  [    0/16396]\n",
      "Test Error: Loss = 0.067901 \n",
      "\n",
      "Epoch 246\n",
      "-------------------------------\n",
      "loss: 0.012660  [    0/16396]\n",
      "Test Error: Loss = 0.066639 \n",
      "\n",
      "Epoch 247\n",
      "-------------------------------\n",
      "loss: 0.012547  [    0/16396]\n",
      "Test Error: Loss = 0.072124 \n",
      "\n",
      "Epoch 248\n",
      "-------------------------------\n",
      "loss: 0.013897  [    0/16396]\n",
      "Test Error: Loss = 0.069997 \n",
      "\n",
      "Epoch 249\n",
      "-------------------------------\n",
      "loss: 0.013832  [    0/16396]\n",
      "Test Error: Loss = 0.068286 \n",
      "\n",
      "Epoch 250\n",
      "-------------------------------\n",
      "loss: 0.012898  [    0/16396]\n",
      "Test Error: Loss = 0.068369 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "### Train the model\n",
    "epochs = 250\n",
    "loss_list=[]\n",
    "test_loss_list=[]\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    loss_list = train(train_loader, model, loss_fn, optimizer,loss_list)\n",
    "    test_loss_list = test(test_loader, model, test_loss_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.plot(loss_list)\n",
    "axes = plt.gca()\n",
    "plt.title('Training Loss')\n",
    "plt.xlabel('time')\n",
    "plt.ylabel('loss')\n",
    "axes.set_ylim([0,0.1])\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(test_loss_list)\n",
    "axes = plt.gca()\n",
    "plt.title('Test Loss')\n",
    "plt.xlabel('data')\n",
    "plt.ylabel('loss')\n",
    "axes.set_ylim([0.04,0.08])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.3945, 0.4629, 0.6316, 0.4648, 0.7711, 0.1407],\n",
      "       grad_fn=<SelectBackward>)\n",
      "tensor([0.3972, 0.4801, 0.6414, 0.2136, 0.7393, 0.1489])\n"
     ]
    }
   ],
   "source": [
    "n = np.random.randint(0,int(0.2*data_trials))\n",
    "pred = model(x_test_tensor[n])\n",
    "print(pred[0])\n",
    "print(y_test_tensor[n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
