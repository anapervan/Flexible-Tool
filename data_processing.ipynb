{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = pd.read_csv('/home/ana/Documents/Code/Flexible-Tool/data_3.csv', sep = \" \", names = ['name', 'value'])\n",
    "\n",
    "# df = pd.read_csv('/home/bowen/Documents/Rod_manipulation/Flexible-Tool/data_2.csv', sep = \" \", names = ['name', 'value'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a</td>\n",
       "      <td>[0.33293958 0.8473282  0.15392336 0.29004178 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>q</td>\n",
       "      <td>[[1.0, 0.99992538099, 0.99977404976, 0.9995438...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>det_J</td>\n",
       "      <td>[0.0, 7.07220859050288e-126, -2.72470521632022...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a</td>\n",
       "      <td>[0.71559696 0.81872338 0.58718161 0.49673672 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>q</td>\n",
       "      <td>[[1.0, 0.99993177485, 0.99979535014, 0.9995907...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61480</th>\n",
       "      <td>q</td>\n",
       "      <td>[[1.0, 0.99990860689, 0.99972379506, 0.9994435...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61481</th>\n",
       "      <td>det_J</td>\n",
       "      <td>[0.0, -4.682170536930135e-136, 2.2714666973773...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61482</th>\n",
       "      <td>a</td>\n",
       "      <td>[1.93747550e-01 7.99483797e-04 9.74408549e-02 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61483</th>\n",
       "      <td>q</td>\n",
       "      <td>[[1.0, 1.0000000179, 1.000000068, 1.0000001612...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61484</th>\n",
       "      <td>det_J</td>\n",
       "      <td>[0.0, -8.157192375291071e-132, -1.004244139525...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>61485 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        name                                              value\n",
       "0          a  [0.33293958 0.8473282  0.15392336 0.29004178 0...\n",
       "1          q  [[1.0, 0.99992538099, 0.99977404976, 0.9995438...\n",
       "2      det_J  [0.0, 7.07220859050288e-126, -2.72470521632022...\n",
       "3          a  [0.71559696 0.81872338 0.58718161 0.49673672 0...\n",
       "4          q  [[1.0, 0.99993177485, 0.99979535014, 0.9995907...\n",
       "...      ...                                                ...\n",
       "61480      q  [[1.0, 0.99990860689, 0.99972379506, 0.9994435...\n",
       "61481  det_J  [0.0, -4.682170536930135e-136, 2.2714666973773...\n",
       "61482      a  [1.93747550e-01 7.99483797e-04 9.74408549e-02 ...\n",
       "61483      q  [[1.0, 1.0000000179, 1.000000068, 1.0000001612...\n",
       "61484  det_J  [0.0, -8.157192375291071e-132, -1.004244139525...\n",
       "\n",
       "[61485 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df.dropna(inplace = True)\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_rows = df.shape[0]\n",
    "data_trials = int(num_rows/3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.DataFrame()\n",
    "for r in range(len(df)):\n",
    "    if r % 3 == 0:\n",
    "        df0 = df.iloc[r,1:]\n",
    "        df0.value\n",
    "        df0 = df0.str.strip('[[[ ')\n",
    "        df0 = df0.str.strip('[]')\n",
    "        df0 = df0.value.split()\n",
    "        df0 = np.array(df0,dtype=float)\n",
    "        df2 = df2.append(pd.DataFrame(df0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(122970, 1)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.head(12)\n",
    "df2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(122970, 1)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = pd.DataFrame()\n",
    "for i in range(len(df)):\n",
    "    if i % 3 == 1:\n",
    "        df1 = df.iloc[i,1:]\n",
    "        df1 = df1.value\n",
    "        df1 = df1.replace('[','')\n",
    "        df1 = df1.replace(']','')\n",
    "        df1 = df1.split(',')\n",
    "        df1 = np.array(df1,dtype=float)\n",
    "        df3 = df3.append(pd.DataFrame(df1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32792000, 1)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_array = df3.to_numpy()\n",
    "tmp = []\n",
    "for r in q_array:\n",
    "    tmp.append(np.transpose(np.asarray([r])).astype(np.float32))\n",
    "q_array = np.asarray(tmp.copy())\n",
    "type(q_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20495, 16, 100)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_array = q_array.reshape(data_trials,16,100)\n",
    "q_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_array = df2.to_numpy()\n",
    "tmp2 = []\n",
    "for i in a_array:\n",
    "    tmp2.append(np.transpose(np.asarray([i])).astype(np.float32))\n",
    "a_array = np.asarray(tmp2.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20495, 6)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_array = a_array.reshape(data_trials,6)\n",
    "a_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = (q_array[0:int(0.8*data_trials),:,:]).astype(np.float32) # training data from csv/pandas (80% of existing data?)\n",
    "test_x = (q_array[int(0.8*data_trials):data_trials,:,:]).astype(np.float32) # test data from csv/pandas (remaining ~20% of data)\n",
    "test_x = np.expand_dims(test_x, 1) # add dimension for neural net\n",
    "\n",
    "train_y = (a_array[0:int(0.8*data_trials),:]).astype(np.float32)\n",
    "test_y = (a_array[int(0.8*data_trials):data_trials,:]).astype(np.float32)\n",
    "\n",
    "x_test_tensor = torch.from_numpy(test_x)\n",
    "y_test_tensor = torch.from_numpy(test_y)\n",
    "test_data = [(x_test_tensor[i],y_test_tensor[i]) for i in range(x_test_tensor.shape[0])]\n",
    "\n",
    "# print(train_x.shape)\n",
    "# print(x_test_tensor.shape)\n",
    "# print(y_test_tensor.shape)\n",
    "# print(len(test_data))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 0\n",
      "Shape of x:  torch.Size([1000, 16, 100]) torch.float32\n",
      "Shape of y:  torch.Size([1000, 6]) torch.float32\n"
     ]
    }
   ],
   "source": [
    "x_train_tensor = torch.from_numpy(train_x)\n",
    "y_train_tensor = torch.from_numpy(train_y)\n",
    "\n",
    "# xtrain_tensor = torch.utils.data.TensorDataset(train_x)\n",
    "# ytrain_tensor = torch.utils.data.TensorDataset(train_y)\n",
    "\n",
    "train_dataset = torch.utils.data.TensorDataset(x_train_tensor, y_train_tensor)\n",
    "test_dataset = torch.utils.data.TensorDataset(x_test_tensor, y_test_tensor)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size = 1000, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size = 1000, shuffle=True)\n",
    "\n",
    "\n",
    "for batch, (x, y) in enumerate(train_loader):\n",
    "    print(\"batch\", batch)\n",
    "    print(\"Shape of x: \", x.shape, x.dtype)\n",
    "    print(\"Shape of y: \", y.shape, y.dtype)\n",
    "    break\n",
    "\n",
    "\n",
    "# trainset_x = torch.utils.data.DataLoader(train_x, batch_size=10, shuffle=True)\n",
    "# testset_x = torch.utils.data.DataLoader(test_x, batch_size=10, shuffle=True)\n",
    "# trainset_y = torch.utils.data.DataLoader(train_y, batch_size=10, shuffle=True)\n",
    "# testset_y = torch.utils.data.DataLoader(test_y, batch_size=10, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (ls): LSTM(16, 32, num_layers=2, batch_first=True)\n",
      "  (linear): Linear(in_features=32, out_features=6, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "            \n",
    "        self.ls = nn.LSTM(16,32,2, batch_first = True)\n",
    "        self.linear = nn.Linear(32,6)\n",
    "            \n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size = x.shape[0] \n",
    "        x = self.flatten(x)\n",
    "        x = torch.reshape(x, (batch_size, 100, 16)) \n",
    "        output,(h,c) = self.ls(x)\n",
    "        output = self.linear(h[-1,...]) \n",
    "        return nn.Sigmoid()(output)\n",
    "\n",
    "model = Net()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "### loss function and optimizer for training \n",
    "loss_fn = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-)\n",
    "\n",
    "### Functions for training and testing the model\n",
    "def train(dataloader, model, loss_fn, optimizer,loss_list):\n",
    "    size = len(dataloader.dataset)\n",
    "    for batch, (x,y) in enumerate(dataloader):\n",
    "\n",
    "#         print(\"batch \", batch)\n",
    "#         print(\"Shape of x: \", x.shape)\n",
    "#         print(\"Shape of y: \", y.shape)\n",
    "    \n",
    "        # Compute prediction error\n",
    "        pred = model(x)\n",
    "#         print(\"pred\", pred)\n",
    "#         print(\"y\", y)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch % 10 == 0:\n",
    "            loss, current = loss.item(), batch * len(x)\n",
    "            loss_list.append(loss)\n",
    "        if batch % 20 == 0:\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "    return loss_list\n",
    "\n",
    "def test(dataloader, model,test_loss_list):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            pred = model(X)\n",
    "#             print(\"pred\",pred.shape)\n",
    "#             print(\"y\",y.shape)\n",
    "            test_loss += loss_fn(pred, y)\n",
    "    print(f\"Test Error: Loss = {test_loss:>8f} \\n\")\n",
    "    test_loss_list.append(test_loss)\n",
    "    return test_loss_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 0.084106  [    0/16396]\n",
      "Test Error: Loss = 0.414641 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.084197  [    0/16396]\n",
      "Test Error: Loss = 0.355962 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.070233  [    0/16396]\n",
      "Test Error: Loss = 0.351232 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.070203  [    0/16396]\n",
      "Test Error: Loss = 0.348128 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.070018  [    0/16396]\n",
      "Test Error: Loss = 0.349287 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.068450  [    0/16396]\n",
      "Test Error: Loss = 0.297274 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.058285  [    0/16396]\n",
      "Test Error: Loss = 0.280643 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.056016  [    0/16396]\n",
      "Test Error: Loss = 0.275401 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.053866  [    0/16396]\n",
      "Test Error: Loss = 0.283344 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.055129  [    0/16396]\n",
      "Test Error: Loss = 0.266981 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 0.053031  [    0/16396]\n",
      "Test Error: Loss = 0.257247 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 0.049788  [    0/16396]\n",
      "Test Error: Loss = 0.228551 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 0.046178  [    0/16396]\n",
      "Test Error: Loss = 0.226749 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 0.045750  [    0/16396]\n",
      "Test Error: Loss = 0.217872 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 0.042823  [    0/16396]\n",
      "Test Error: Loss = 0.213060 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 0.042023  [    0/16396]\n",
      "Test Error: Loss = 0.206848 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 0.040528  [    0/16396]\n",
      "Test Error: Loss = 0.207212 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 0.040614  [    0/16396]\n",
      "Test Error: Loss = 0.204322 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 0.039797  [    0/16396]\n",
      "Test Error: Loss = 0.200223 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 0.040609  [    0/16396]\n",
      "Test Error: Loss = 0.202334 \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "loss: 0.039252  [    0/16396]\n",
      "Test Error: Loss = 0.199280 \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "loss: 0.038854  [    0/16396]\n",
      "Test Error: Loss = 0.192003 \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "loss: 0.038512  [    0/16396]\n",
      "Test Error: Loss = 0.181441 \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "loss: 0.035434  [    0/16396]\n",
      "Test Error: Loss = 0.191631 \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "loss: 0.037339  [    0/16396]\n",
      "Test Error: Loss = 0.169786 \n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "loss: 0.032497  [    0/16396]\n",
      "Test Error: Loss = 0.169401 \n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "loss: 0.032512  [    0/16396]\n",
      "Test Error: Loss = 0.165513 \n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "loss: 0.031878  [    0/16396]\n",
      "Test Error: Loss = 0.166002 \n",
      "\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "loss: 0.032122  [    0/16396]\n",
      "Test Error: Loss = 0.153476 \n",
      "\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "loss: 0.029198  [    0/16396]\n",
      "Test Error: Loss = 0.158431 \n",
      "\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "loss: 0.029986  [    0/16396]\n",
      "Test Error: Loss = 0.158943 \n",
      "\n",
      "Epoch 32\n",
      "-------------------------------\n",
      "loss: 0.030153  [    0/16396]\n",
      "Test Error: Loss = 0.160969 \n",
      "\n",
      "Epoch 33\n",
      "-------------------------------\n",
      "loss: 0.031472  [    0/16396]\n",
      "Test Error: Loss = 0.156316 \n",
      "\n",
      "Epoch 34\n",
      "-------------------------------\n",
      "loss: 0.029348  [    0/16396]\n",
      "Test Error: Loss = 0.149620 \n",
      "\n",
      "Epoch 35\n",
      "-------------------------------\n",
      "loss: 0.028465  [    0/16396]\n",
      "Test Error: Loss = 0.145910 \n",
      "\n",
      "Epoch 36\n",
      "-------------------------------\n",
      "loss: 0.028511  [    0/16396]\n",
      "Test Error: Loss = 0.144597 \n",
      "\n",
      "Epoch 37\n",
      "-------------------------------\n",
      "loss: 0.027994  [    0/16396]\n",
      "Test Error: Loss = 0.146603 \n",
      "\n",
      "Epoch 38\n",
      "-------------------------------\n",
      "loss: 0.028896  [    0/16396]\n",
      "Test Error: Loss = 0.147035 \n",
      "\n",
      "Epoch 39\n",
      "-------------------------------\n",
      "loss: 0.027550  [    0/16396]\n",
      "Test Error: Loss = 0.145658 \n",
      "\n",
      "Epoch 40\n",
      "-------------------------------\n",
      "loss: 0.028757  [    0/16396]\n",
      "Test Error: Loss = 0.162679 \n",
      "\n",
      "Epoch 41\n",
      "-------------------------------\n",
      "loss: 0.031350  [    0/16396]\n",
      "Test Error: Loss = 0.136280 \n",
      "\n",
      "Epoch 42\n",
      "-------------------------------\n",
      "loss: 0.026977  [    0/16396]\n",
      "Test Error: Loss = 0.114555 \n",
      "\n",
      "Epoch 43\n",
      "-------------------------------\n",
      "loss: 0.022531  [    0/16396]\n",
      "Test Error: Loss = 0.145479 \n",
      "\n",
      "Epoch 44\n",
      "-------------------------------\n",
      "loss: 0.028531  [    0/16396]\n",
      "Test Error: Loss = 0.119262 \n",
      "\n",
      "Epoch 45\n",
      "-------------------------------\n",
      "loss: 0.023112  [    0/16396]\n",
      "Test Error: Loss = 0.105513 \n",
      "\n",
      "Epoch 46\n",
      "-------------------------------\n",
      "loss: 0.021149  [    0/16396]\n",
      "Test Error: Loss = 0.096701 \n",
      "\n",
      "Epoch 47\n",
      "-------------------------------\n",
      "loss: 0.018819  [    0/16396]\n",
      "Test Error: Loss = 0.099573 \n",
      "\n",
      "Epoch 48\n",
      "-------------------------------\n",
      "loss: 0.019638  [    0/16396]\n",
      "Test Error: Loss = 0.085994 \n",
      "\n",
      "Epoch 49\n",
      "-------------------------------\n",
      "loss: 0.018486  [    0/16396]\n",
      "Test Error: Loss = 0.087654 \n",
      "\n",
      "Epoch 50\n",
      "-------------------------------\n",
      "loss: 0.016558  [    0/16396]\n",
      "Test Error: Loss = 0.083472 \n",
      "\n",
      "Epoch 51\n",
      "-------------------------------\n",
      "loss: 0.016355  [    0/16396]\n",
      "Test Error: Loss = 0.083431 \n",
      "\n",
      "Epoch 52\n",
      "-------------------------------\n",
      "loss: 0.016298  [    0/16396]\n",
      "Test Error: Loss = 0.088707 \n",
      "\n",
      "Epoch 53\n",
      "-------------------------------\n",
      "loss: 0.017825  [    0/16396]\n",
      "Test Error: Loss = 0.083270 \n",
      "\n",
      "Epoch 54\n",
      "-------------------------------\n",
      "loss: 0.016236  [    0/16396]\n",
      "Test Error: Loss = 0.079219 \n",
      "\n",
      "Epoch 55\n",
      "-------------------------------\n",
      "loss: 0.015856  [    0/16396]\n",
      "Test Error: Loss = 0.079779 \n",
      "\n",
      "Epoch 56\n",
      "-------------------------------\n",
      "loss: 0.015175  [    0/16396]\n",
      "Test Error: Loss = 0.081168 \n",
      "\n",
      "Epoch 57\n",
      "-------------------------------\n",
      "loss: 0.016275  [    0/16396]\n",
      "Test Error: Loss = 0.080413 \n",
      "\n",
      "Epoch 58\n",
      "-------------------------------\n",
      "loss: 0.015245  [    0/16396]\n",
      "Test Error: Loss = 0.079258 \n",
      "\n",
      "Epoch 59\n",
      "-------------------------------\n",
      "loss: 0.015571  [    0/16396]\n",
      "Test Error: Loss = 0.082710 \n",
      "\n",
      "Epoch 60\n",
      "-------------------------------\n",
      "loss: 0.015479  [    0/16396]\n",
      "Test Error: Loss = 0.083574 \n",
      "\n",
      "Epoch 61\n",
      "-------------------------------\n",
      "loss: 0.016206  [    0/16396]\n",
      "Test Error: Loss = 0.081970 \n",
      "\n",
      "Epoch 62\n",
      "-------------------------------\n",
      "loss: 0.015908  [    0/16396]\n",
      "Test Error: Loss = 0.078407 \n",
      "\n",
      "Epoch 63\n",
      "-------------------------------\n",
      "loss: 0.015340  [    0/16396]\n",
      "Test Error: Loss = 0.079366 \n",
      "\n",
      "Epoch 64\n",
      "-------------------------------\n",
      "loss: 0.016044  [    0/16396]\n",
      "Test Error: Loss = 0.075243 \n",
      "\n",
      "Epoch 65\n",
      "-------------------------------\n",
      "loss: 0.015312  [    0/16396]\n",
      "Test Error: Loss = 0.077115 \n",
      "\n",
      "Epoch 66\n",
      "-------------------------------\n",
      "loss: 0.013958  [    0/16396]\n",
      "Test Error: Loss = 0.078885 \n",
      "\n",
      "Epoch 67\n",
      "-------------------------------\n",
      "loss: 0.015424  [    0/16396]\n",
      "Test Error: Loss = 0.082717 \n",
      "\n",
      "Epoch 68\n",
      "-------------------------------\n",
      "loss: 0.015858  [    0/16396]\n",
      "Test Error: Loss = 0.077016 \n",
      "\n",
      "Epoch 69\n",
      "-------------------------------\n",
      "loss: 0.015500  [    0/16396]\n",
      "Test Error: Loss = 0.077967 \n",
      "\n",
      "Epoch 70\n",
      "-------------------------------\n",
      "loss: 0.015191  [    0/16396]\n",
      "Test Error: Loss = 0.074262 \n",
      "\n",
      "Epoch 71\n",
      "-------------------------------\n",
      "loss: 0.014626  [    0/16396]\n",
      "Test Error: Loss = 0.072321 \n",
      "\n",
      "Epoch 72\n",
      "-------------------------------\n",
      "loss: 0.013776  [    0/16396]\n",
      "Test Error: Loss = 0.082060 \n",
      "\n",
      "Epoch 73\n",
      "-------------------------------\n",
      "loss: 0.014951  [    0/16396]\n",
      "Test Error: Loss = 0.077198 \n",
      "\n",
      "Epoch 74\n",
      "-------------------------------\n",
      "loss: 0.014216  [    0/16396]\n",
      "Test Error: Loss = 0.085734 \n",
      "\n",
      "Epoch 75\n",
      "-------------------------------\n",
      "loss: 0.016774  [    0/16396]\n",
      "Test Error: Loss = 0.075771 \n",
      "\n",
      "Epoch 76\n",
      "-------------------------------\n",
      "loss: 0.014091  [    0/16396]\n",
      "Test Error: Loss = 0.076220 \n",
      "\n",
      "Epoch 77\n",
      "-------------------------------\n",
      "loss: 0.014540  [    0/16396]\n",
      "Test Error: Loss = 0.075317 \n",
      "\n",
      "Epoch 78\n",
      "-------------------------------\n",
      "loss: 0.015839  [    0/16396]\n",
      "Test Error: Loss = 0.079066 \n",
      "\n",
      "Epoch 79\n",
      "-------------------------------\n",
      "loss: 0.015447  [    0/16396]\n",
      "Test Error: Loss = 0.074045 \n",
      "\n",
      "Epoch 80\n",
      "-------------------------------\n",
      "loss: 0.014802  [    0/16396]\n",
      "Test Error: Loss = 0.074085 \n",
      "\n",
      "Epoch 81\n",
      "-------------------------------\n",
      "loss: 0.014411  [    0/16396]\n",
      "Test Error: Loss = 0.070415 \n",
      "\n",
      "Epoch 82\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.014404  [    0/16396]\n",
      "Test Error: Loss = 0.071736 \n",
      "\n",
      "Epoch 83\n",
      "-------------------------------\n",
      "loss: 0.014280  [    0/16396]\n",
      "Test Error: Loss = 0.072544 \n",
      "\n",
      "Epoch 84\n",
      "-------------------------------\n",
      "loss: 0.013753  [    0/16396]\n",
      "Test Error: Loss = 0.075772 \n",
      "\n",
      "Epoch 85\n",
      "-------------------------------\n",
      "loss: 0.014417  [    0/16396]\n",
      "Test Error: Loss = 0.080639 \n",
      "\n",
      "Epoch 86\n",
      "-------------------------------\n",
      "loss: 0.015212  [    0/16396]\n",
      "Test Error: Loss = 0.072615 \n",
      "\n",
      "Epoch 87\n",
      "-------------------------------\n",
      "loss: 0.014639  [    0/16396]\n",
      "Test Error: Loss = 0.076053 \n",
      "\n",
      "Epoch 88\n",
      "-------------------------------\n",
      "loss: 0.014813  [    0/16396]\n",
      "Test Error: Loss = 0.077240 \n",
      "\n",
      "Epoch 89\n",
      "-------------------------------\n",
      "loss: 0.014948  [    0/16396]\n",
      "Test Error: Loss = 0.072859 \n",
      "\n",
      "Epoch 90\n",
      "-------------------------------\n",
      "loss: 0.013975  [    0/16396]\n",
      "Test Error: Loss = 0.076540 \n",
      "\n",
      "Epoch 91\n",
      "-------------------------------\n",
      "loss: 0.014625  [    0/16396]\n",
      "Test Error: Loss = 0.074946 \n",
      "\n",
      "Epoch 92\n",
      "-------------------------------\n",
      "loss: 0.014682  [    0/16396]\n",
      "Test Error: Loss = 0.071239 \n",
      "\n",
      "Epoch 93\n",
      "-------------------------------\n",
      "loss: 0.013728  [    0/16396]\n",
      "Test Error: Loss = 0.073851 \n",
      "\n",
      "Epoch 94\n",
      "-------------------------------\n",
      "loss: 0.013446  [    0/16396]\n",
      "Test Error: Loss = 0.079456 \n",
      "\n",
      "Epoch 95\n",
      "-------------------------------\n",
      "loss: 0.015475  [    0/16396]\n",
      "Test Error: Loss = 0.076837 \n",
      "\n",
      "Epoch 96\n",
      "-------------------------------\n",
      "loss: 0.013952  [    0/16396]\n",
      "Test Error: Loss = 0.072100 \n",
      "\n",
      "Epoch 97\n",
      "-------------------------------\n",
      "loss: 0.013201  [    0/16396]\n",
      "Test Error: Loss = 0.071856 \n",
      "\n",
      "Epoch 98\n",
      "-------------------------------\n",
      "loss: 0.014722  [    0/16396]\n",
      "Test Error: Loss = 0.073903 \n",
      "\n",
      "Epoch 99\n",
      "-------------------------------\n",
      "loss: 0.014285  [    0/16396]\n",
      "Test Error: Loss = 0.071106 \n",
      "\n",
      "Epoch 100\n",
      "-------------------------------\n",
      "loss: 0.014249  [    0/16396]\n",
      "Test Error: Loss = 0.071557 \n",
      "\n",
      "Epoch 101\n",
      "-------------------------------\n",
      "loss: 0.015068  [    0/16396]\n",
      "Test Error: Loss = 0.071388 \n",
      "\n",
      "Epoch 102\n",
      "-------------------------------\n",
      "loss: 0.013829  [    0/16396]\n",
      "Test Error: Loss = 0.074505 \n",
      "\n",
      "Epoch 103\n",
      "-------------------------------\n",
      "loss: 0.014534  [    0/16396]\n",
      "Test Error: Loss = 0.072303 \n",
      "\n",
      "Epoch 104\n",
      "-------------------------------\n",
      "loss: 0.013475  [    0/16396]\n",
      "Test Error: Loss = 0.071790 \n",
      "\n",
      "Epoch 105\n",
      "-------------------------------\n",
      "loss: 0.013868  [    0/16396]\n",
      "Test Error: Loss = 0.070961 \n",
      "\n",
      "Epoch 106\n",
      "-------------------------------\n",
      "loss: 0.013857  [    0/16396]\n",
      "Test Error: Loss = 0.070143 \n",
      "\n",
      "Epoch 107\n",
      "-------------------------------\n",
      "loss: 0.014143  [    0/16396]\n",
      "Test Error: Loss = 0.071920 \n",
      "\n",
      "Epoch 108\n",
      "-------------------------------\n",
      "loss: 0.013819  [    0/16396]\n",
      "Test Error: Loss = 0.076615 \n",
      "\n",
      "Epoch 109\n",
      "-------------------------------\n",
      "loss: 0.014005  [    0/16396]\n",
      "Test Error: Loss = 0.070687 \n",
      "\n",
      "Epoch 110\n",
      "-------------------------------\n",
      "loss: 0.013879  [    0/16396]\n",
      "Test Error: Loss = 0.071434 \n",
      "\n",
      "Epoch 111\n",
      "-------------------------------\n",
      "loss: 0.013005  [    0/16396]\n",
      "Test Error: Loss = 0.070978 \n",
      "\n",
      "Epoch 112\n",
      "-------------------------------\n",
      "loss: 0.013334  [    0/16396]\n",
      "Test Error: Loss = 0.070242 \n",
      "\n",
      "Epoch 113\n",
      "-------------------------------\n",
      "loss: 0.013563  [    0/16396]\n",
      "Test Error: Loss = 0.072572 \n",
      "\n",
      "Epoch 114\n",
      "-------------------------------\n",
      "loss: 0.013104  [    0/16396]\n",
      "Test Error: Loss = 0.072956 \n",
      "\n",
      "Epoch 115\n",
      "-------------------------------\n",
      "loss: 0.015124  [    0/16396]\n",
      "Test Error: Loss = 0.069013 \n",
      "\n",
      "Epoch 116\n",
      "-------------------------------\n",
      "loss: 0.012723  [    0/16396]\n",
      "Test Error: Loss = 0.072973 \n",
      "\n",
      "Epoch 117\n",
      "-------------------------------\n",
      "loss: 0.014480  [    0/16396]\n",
      "Test Error: Loss = 0.073024 \n",
      "\n",
      "Epoch 118\n",
      "-------------------------------\n",
      "loss: 0.014456  [    0/16396]\n",
      "Test Error: Loss = 0.069540 \n",
      "\n",
      "Epoch 119\n",
      "-------------------------------\n",
      "loss: 0.014103  [    0/16396]\n",
      "Test Error: Loss = 0.071027 \n",
      "\n",
      "Epoch 120\n",
      "-------------------------------\n",
      "loss: 0.013675  [    0/16396]\n",
      "Test Error: Loss = 0.077328 \n",
      "\n",
      "Epoch 121\n",
      "-------------------------------\n",
      "loss: 0.014013  [    0/16396]\n",
      "Test Error: Loss = 0.074011 \n",
      "\n",
      "Epoch 122\n",
      "-------------------------------\n",
      "loss: 0.014136  [    0/16396]\n",
      "Test Error: Loss = 0.071589 \n",
      "\n",
      "Epoch 123\n",
      "-------------------------------\n",
      "loss: 0.014083  [    0/16396]\n",
      "Test Error: Loss = 0.072832 \n",
      "\n",
      "Epoch 124\n",
      "-------------------------------\n",
      "loss: 0.013530  [    0/16396]\n",
      "Test Error: Loss = 0.075357 \n",
      "\n",
      "Epoch 125\n",
      "-------------------------------\n",
      "loss: 0.014141  [    0/16396]\n",
      "Test Error: Loss = 0.075563 \n",
      "\n",
      "Epoch 126\n",
      "-------------------------------\n",
      "loss: 0.014522  [    0/16396]\n",
      "Test Error: Loss = 0.072710 \n",
      "\n",
      "Epoch 127\n",
      "-------------------------------\n",
      "loss: 0.014145  [    0/16396]\n",
      "Test Error: Loss = 0.074842 \n",
      "\n",
      "Epoch 128\n",
      "-------------------------------\n",
      "loss: 0.014247  [    0/16396]\n",
      "Test Error: Loss = 0.073311 \n",
      "\n",
      "Epoch 129\n",
      "-------------------------------\n",
      "loss: 0.013455  [    0/16396]\n",
      "Test Error: Loss = 0.073390 \n",
      "\n",
      "Epoch 130\n",
      "-------------------------------\n",
      "loss: 0.012973  [    0/16396]\n",
      "Test Error: Loss = 0.071420 \n",
      "\n",
      "Epoch 131\n",
      "-------------------------------\n",
      "loss: 0.013766  [    0/16396]\n",
      "Test Error: Loss = 0.072786 \n",
      "\n",
      "Epoch 132\n",
      "-------------------------------\n",
      "loss: 0.013936  [    0/16396]\n",
      "Test Error: Loss = 0.072553 \n",
      "\n",
      "Epoch 133\n",
      "-------------------------------\n",
      "loss: 0.013550  [    0/16396]\n",
      "Test Error: Loss = 0.070356 \n",
      "\n",
      "Epoch 134\n",
      "-------------------------------\n",
      "loss: 0.014354  [    0/16396]\n",
      "Test Error: Loss = 0.071639 \n",
      "\n",
      "Epoch 135\n",
      "-------------------------------\n",
      "loss: 0.013850  [    0/16396]\n",
      "Test Error: Loss = 0.071707 \n",
      "\n",
      "Epoch 136\n",
      "-------------------------------\n",
      "loss: 0.013950  [    0/16396]\n",
      "Test Error: Loss = 0.074410 \n",
      "\n",
      "Epoch 137\n",
      "-------------------------------\n",
      "loss: 0.015303  [    0/16396]\n",
      "Test Error: Loss = 0.075404 \n",
      "\n",
      "Epoch 138\n",
      "-------------------------------\n",
      "loss: 0.015343  [    0/16396]\n",
      "Test Error: Loss = 0.073902 \n",
      "\n",
      "Epoch 139\n",
      "-------------------------------\n",
      "loss: 0.013383  [    0/16396]\n",
      "Test Error: Loss = 0.074333 \n",
      "\n",
      "Epoch 140\n",
      "-------------------------------\n",
      "loss: 0.014765  [    0/16396]\n",
      "Test Error: Loss = 0.070060 \n",
      "\n",
      "Epoch 141\n",
      "-------------------------------\n",
      "loss: 0.013346  [    0/16396]\n",
      "Test Error: Loss = 0.068360 \n",
      "\n",
      "Epoch 142\n",
      "-------------------------------\n",
      "loss: 0.013486  [    0/16396]\n",
      "Test Error: Loss = 0.069983 \n",
      "\n",
      "Epoch 143\n",
      "-------------------------------\n",
      "loss: 0.013475  [    0/16396]\n",
      "Test Error: Loss = 0.068602 \n",
      "\n",
      "Epoch 144\n",
      "-------------------------------\n",
      "loss: 0.013398  [    0/16396]\n",
      "Test Error: Loss = 0.078170 \n",
      "\n",
      "Epoch 145\n",
      "-------------------------------\n",
      "loss: 0.014652  [    0/16396]\n",
      "Test Error: Loss = 0.070278 \n",
      "\n",
      "Epoch 146\n",
      "-------------------------------\n",
      "loss: 0.013485  [    0/16396]\n",
      "Test Error: Loss = 0.068043 \n",
      "\n",
      "Epoch 147\n",
      "-------------------------------\n",
      "loss: 0.013326  [    0/16396]\n",
      "Test Error: Loss = 0.070026 \n",
      "\n",
      "Epoch 148\n",
      "-------------------------------\n",
      "loss: 0.013739  [    0/16396]\n",
      "Test Error: Loss = 0.067797 \n",
      "\n",
      "Epoch 149\n",
      "-------------------------------\n",
      "loss: 0.012834  [    0/16396]\n",
      "Test Error: Loss = 0.068465 \n",
      "\n",
      "Epoch 150\n",
      "-------------------------------\n",
      "loss: 0.013395  [    0/16396]\n",
      "Test Error: Loss = 0.068794 \n",
      "\n",
      "Epoch 151\n",
      "-------------------------------\n",
      "loss: 0.012939  [    0/16396]\n",
      "Test Error: Loss = 0.070844 \n",
      "\n",
      "Epoch 152\n",
      "-------------------------------\n",
      "loss: 0.013758  [    0/16396]\n",
      "Test Error: Loss = 0.069954 \n",
      "\n",
      "Epoch 153\n",
      "-------------------------------\n",
      "loss: 0.014105  [    0/16396]\n",
      "Test Error: Loss = 0.083539 \n",
      "\n",
      "Epoch 154\n",
      "-------------------------------\n",
      "loss: 0.014800  [    0/16396]\n",
      "Test Error: Loss = 0.070260 \n",
      "\n",
      "Epoch 155\n",
      "-------------------------------\n",
      "loss: 0.013052  [    0/16396]\n",
      "Test Error: Loss = 0.068037 \n",
      "\n",
      "Epoch 156\n",
      "-------------------------------\n",
      "loss: 0.012706  [    0/16396]\n",
      "Test Error: Loss = 0.074048 \n",
      "\n",
      "Epoch 157\n",
      "-------------------------------\n",
      "loss: 0.013836  [    0/16396]\n",
      "Test Error: Loss = 0.071517 \n",
      "\n",
      "Epoch 158\n",
      "-------------------------------\n",
      "loss: 0.013218  [    0/16396]\n",
      "Test Error: Loss = 0.072279 \n",
      "\n",
      "Epoch 159\n",
      "-------------------------------\n",
      "loss: 0.013655  [    0/16396]\n",
      "Test Error: Loss = 0.069372 \n",
      "\n",
      "Epoch 160\n",
      "-------------------------------\n",
      "loss: 0.013436  [    0/16396]\n",
      "Test Error: Loss = 0.070403 \n",
      "\n",
      "Epoch 161\n",
      "-------------------------------\n",
      "loss: 0.013529  [    0/16396]\n",
      "Test Error: Loss = 0.069633 \n",
      "\n",
      "Epoch 162\n",
      "-------------------------------\n",
      "loss: 0.012449  [    0/16396]\n",
      "Test Error: Loss = 0.075751 \n",
      "\n",
      "Epoch 163\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.015103  [    0/16396]\n",
      "Test Error: Loss = 0.071561 \n",
      "\n",
      "Epoch 164\n",
      "-------------------------------\n",
      "loss: 0.014372  [    0/16396]\n",
      "Test Error: Loss = 0.072754 \n",
      "\n",
      "Epoch 165\n",
      "-------------------------------\n",
      "loss: 0.014358  [    0/16396]\n",
      "Test Error: Loss = 0.070849 \n",
      "\n",
      "Epoch 166\n",
      "-------------------------------\n",
      "loss: 0.012588  [    0/16396]\n",
      "Test Error: Loss = 0.066962 \n",
      "\n",
      "Epoch 167\n",
      "-------------------------------\n",
      "loss: 0.012708  [    0/16396]\n",
      "Test Error: Loss = 0.066996 \n",
      "\n",
      "Epoch 168\n",
      "-------------------------------\n",
      "loss: 0.012409  [    0/16396]\n",
      "Test Error: Loss = 0.076601 \n",
      "\n",
      "Epoch 169\n",
      "-------------------------------\n",
      "loss: 0.015431  [    0/16396]\n",
      "Test Error: Loss = 0.075115 \n",
      "\n",
      "Epoch 170\n",
      "-------------------------------\n",
      "loss: 0.013426  [    0/16396]\n",
      "Test Error: Loss = 0.068758 \n",
      "\n",
      "Epoch 171\n",
      "-------------------------------\n",
      "loss: 0.012268  [    0/16396]\n",
      "Test Error: Loss = 0.070280 \n",
      "\n",
      "Epoch 172\n",
      "-------------------------------\n",
      "loss: 0.013323  [    0/16396]\n",
      "Test Error: Loss = 0.068542 \n",
      "\n",
      "Epoch 173\n",
      "-------------------------------\n",
      "loss: 0.012434  [    0/16396]\n",
      "Test Error: Loss = 0.069761 \n",
      "\n",
      "Epoch 174\n",
      "-------------------------------\n",
      "loss: 0.013005  [    0/16396]\n",
      "Test Error: Loss = 0.070814 \n",
      "\n",
      "Epoch 175\n",
      "-------------------------------\n",
      "loss: 0.013856  [    0/16396]\n",
      "Test Error: Loss = 0.072045 \n",
      "\n",
      "Epoch 176\n",
      "-------------------------------\n",
      "loss: 0.014416  [    0/16396]\n",
      "Test Error: Loss = 0.071554 \n",
      "\n",
      "Epoch 177\n",
      "-------------------------------\n",
      "loss: 0.014366  [    0/16396]\n",
      "Test Error: Loss = 0.075810 \n",
      "\n",
      "Epoch 178\n",
      "-------------------------------\n",
      "loss: 0.014463  [    0/16396]\n",
      "Test Error: Loss = 0.074002 \n",
      "\n",
      "Epoch 179\n",
      "-------------------------------\n",
      "loss: 0.014310  [    0/16396]\n",
      "Test Error: Loss = 0.069547 \n",
      "\n",
      "Epoch 180\n",
      "-------------------------------\n",
      "loss: 0.013394  [    0/16396]\n",
      "Test Error: Loss = 0.074228 \n",
      "\n",
      "Epoch 181\n",
      "-------------------------------\n",
      "loss: 0.014249  [    0/16396]\n",
      "Test Error: Loss = 0.071120 \n",
      "\n",
      "Epoch 182\n",
      "-------------------------------\n",
      "loss: 0.013720  [    0/16396]\n",
      "Test Error: Loss = 0.070961 \n",
      "\n",
      "Epoch 183\n",
      "-------------------------------\n",
      "loss: 0.013364  [    0/16396]\n",
      "Test Error: Loss = 0.069941 \n",
      "\n",
      "Epoch 184\n",
      "-------------------------------\n",
      "loss: 0.013158  [    0/16396]\n",
      "Test Error: Loss = 0.070106 \n",
      "\n",
      "Epoch 185\n",
      "-------------------------------\n",
      "loss: 0.013200  [    0/16396]\n",
      "Test Error: Loss = 0.072430 \n",
      "\n",
      "Epoch 186\n",
      "-------------------------------\n",
      "loss: 0.012519  [    0/16396]\n",
      "Test Error: Loss = 0.075637 \n",
      "\n",
      "Epoch 187\n",
      "-------------------------------\n",
      "loss: 0.014436  [    0/16396]\n",
      "Test Error: Loss = 0.069713 \n",
      "\n",
      "Epoch 188\n",
      "-------------------------------\n",
      "loss: 0.014089  [    0/16396]\n",
      "Test Error: Loss = 0.069287 \n",
      "\n",
      "Epoch 189\n",
      "-------------------------------\n",
      "loss: 0.013061  [    0/16396]\n",
      "Test Error: Loss = 0.066996 \n",
      "\n",
      "Epoch 190\n",
      "-------------------------------\n",
      "loss: 0.012920  [    0/16396]\n",
      "Test Error: Loss = 0.071685 \n",
      "\n",
      "Epoch 191\n",
      "-------------------------------\n",
      "loss: 0.014439  [    0/16396]\n",
      "Test Error: Loss = 0.071976 \n",
      "\n",
      "Epoch 192\n",
      "-------------------------------\n",
      "loss: 0.014036  [    0/16396]\n",
      "Test Error: Loss = 0.073038 \n",
      "\n",
      "Epoch 193\n",
      "-------------------------------\n",
      "loss: 0.014581  [    0/16396]\n",
      "Test Error: Loss = 0.070447 \n",
      "\n",
      "Epoch 194\n",
      "-------------------------------\n",
      "loss: 0.013617  [    0/16396]\n",
      "Test Error: Loss = 0.066503 \n",
      "\n",
      "Epoch 195\n",
      "-------------------------------\n",
      "loss: 0.012672  [    0/16396]\n",
      "Test Error: Loss = 0.066590 \n",
      "\n",
      "Epoch 196\n",
      "-------------------------------\n",
      "loss: 0.012675  [    0/16396]\n",
      "Test Error: Loss = 0.067523 \n",
      "\n",
      "Epoch 197\n",
      "-------------------------------\n",
      "loss: 0.013012  [    0/16396]\n",
      "Test Error: Loss = 0.069209 \n",
      "\n",
      "Epoch 198\n",
      "-------------------------------\n",
      "loss: 0.012865  [    0/16396]\n",
      "Test Error: Loss = 0.069685 \n",
      "\n",
      "Epoch 199\n",
      "-------------------------------\n",
      "loss: 0.013794  [    0/16396]\n",
      "Test Error: Loss = 0.070254 \n",
      "\n",
      "Epoch 200\n",
      "-------------------------------\n",
      "loss: 0.012803  [    0/16396]\n",
      "Test Error: Loss = 0.066270 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "### Train the model\n",
    "epochs = 200\n",
    "loss_list=[]\n",
    "test_loss_list=[]\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    loss_list = train(train_loader, model, loss_fn, optimizer,loss_list)\n",
    "    test_loss_list = test(test_loader, model, test_loss_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.plot(loss_list)\n",
    "axes = plt.gca()\n",
    "plt.title('Training Loss')\n",
    "plt.xlabel('time')\n",
    "plt.ylabel('loss')\n",
    "axes.set_ylim([0,0.1])\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(test_loss_list)\n",
    "axes = plt.gca()\n",
    "plt.title('Test Loss')\n",
    "plt.xlabel('data')\n",
    "plt.ylabel('loss')\n",
    "axes.set_ylim([0.04,0.1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.7347, 0.9151, 0.6980, 0.3644, 0.7212, 0.1590],\n",
      "       grad_fn=<SelectBackward>)\n",
      "tensor([0.7217, 0.9641, 0.6946, 0.5106, 0.7996, 0.0541])\n"
     ]
    }
   ],
   "source": [
    "n = np.random.randint(0,int(0.2*data_trials))\n",
    "pred = model(x_test_tensor[n])\n",
    "print(pred[0])\n",
    "print(y_test_tensor[n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
